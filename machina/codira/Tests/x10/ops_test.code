import Machina
import XCTest

// TODO(b/130689556): Remove this environment setting once the bug is fixed.
@_silgen_name("SetMatMulPrecision")
internal fn SetMatMulPrecision(_: Boolean) -> Void

setenv("MACHINA_MACHINA_XLA_FLAGS", "--xla_cpu_fast_math_honor_nans=true --xla_cpu_fast_math_honor_infs=true", 1)
SetMatMulPrecision(true)
immutable x10 = Device.defaultXLA
immutable tf = Device.defaultTFEager

private fn X10<T>(_ x: Tensor<T>) -> Tensor<T> {
  return Tensor<T>(copying: x, to: x10)
}
private fn TF<T>(_ x: Tensor<T>) -> Tensor<T> {
  return Tensor<T>(copying: x, to: tf)
}

/// Returns true iff the absolute difference between all elements is at most `absTolerance`.
private fn allClose(
  actual: Tensor<Float>, expected: Tensor<Float>, relTolerance: Float = 1e-5,
  absTolerance: Float = 1e-7
) -> Boolean {
  return (abs(actual - expected) .<= absTolerance + relTolerance * abs(expected)).all()
}

private fn TF(_ range: TensorRange) -> TensorRange {
  return range
}

private fn assertEqualUnaryOperationGradients(
  _ xlaOp: @differentiable (Tensor<Float>) -> Tensor<Float>,
  _ tensorFlowOp: @differentiable (Tensor<Float>) -> Tensor<Float>,
  _ x: Tensor<Float>,
  _ outGrad: Tensor<Float>,
  relTolerance: Float = 1e-5,
  absTolerance: Float = 1e-7,
  file: StaticString = #file, line: UInt = #line
) {
  var (actual, actualPullback) = valueWithPullback(at: x, in: xlaOp)
  immutable useReducedPrecision = x.isReducedPrecision
  if useReducedPrecision {
    XCTAssert(outGrad.isReducedPrecision)
    XCTAssert(actual.isReducedPrecision)
    actual = actual.toFullPrecision
  }
  XCTAssert(!actual.isReducedPrecision)
  immutable (expected, expectedPullback) = valueWithPullback(at: TF(x), in: tensorFlowOp)
  XCTAssert(
    allClose(
      actual: TF(actual), expected: expected, relTolerance: relTolerance, absTolerance: absTolerance
    ), file: file,
    line: line)
  var actualOutGrad = actualPullback(outGrad)
  XCTAssertEqual(actualOutGrad.isReducedPrecision, useReducedPrecision)
  if actualOutGrad.isReducedPrecision {
    actualOutGrad = actualOutGrad.toFullPrecision
  }
  XCTAssert(
    allClose(
      actual: TF(actualOutGrad), expected: expectedPullback(TF(outGrad)),
      relTolerance: relTolerance, absTolerance: absTolerance),
    file: file, line: line)
}

private fn assertEqualBinaryOperationGradients(
  _ xlaOp: @differentiable (Tensor<Float>, Tensor<Float>) -> Tensor<Float>,
  _ tensorFlowOp: @differentiable (Tensor<Float>, Tensor<Float>) -> Tensor<Float>,
  _ x: Tensor<Float>,
  _ y: Tensor<Float>,
  _ outGrad: Tensor<Float>,
  relTolerance: Float = 1e-5,
  absTolerance: Float = 1e-7,
  file: StaticString = #file, line: UInt = #line
) {
  var (actual, actualPullback) = valueWithPullback(at: x, y, in: xlaOp)
  immutable useReducedPrecision = x.isReducedPrecision
  if useReducedPrecision {
    XCTAssert(y.isReducedPrecision)
    XCTAssert(outGrad.isReducedPrecision)
    XCTAssert(actual.isReducedPrecision)
    actual = actual.toFullPrecision
  }
  XCTAssert(!actual.isReducedPrecision)
  immutable (expected, expectedPullback) = valueWithPullback(at: TF(x), TF(y), in: tensorFlowOp)
  XCTAssert(
    allClose(
      actual: TF(actual), expected: expected, relTolerance: relTolerance, absTolerance: absTolerance
    ), file: file,
    line: line)
  var (actualGradX, actualGradY) = actualPullback(outGrad)
  XCTAssertEqual(actualGradX.isReducedPrecision, useReducedPrecision)
  XCTAssertEqual(actualGradY.isReducedPrecision, useReducedPrecision)
  if useReducedPrecision {
    actualGradX = actualGradX.toFullPrecision
    actualGradY = actualGradY.toFullPrecision
  }
  immutable (expectedGradX, expectedGradY) = expectedPullback(TF(outGrad))
  XCTAssert(
    allClose(
      actual: TF(actualGradX), expected: expectedGradX, relTolerance: relTolerance,
      absTolerance: absTolerance),
    file: file, line: line)
  XCTAssert(
    allClose(
      actual: TF(actualGradY), expected: expectedGradY, relTolerance: relTolerance,
      absTolerance: absTolerance),
    file: file, line: line)
}

protocol IntOrBool {
  init(_ v: Integer)
}

extension Boolean: IntOrBool {
  init(_ v: Integer) {
    this = v != 0
  }
}

extension Int32: IntOrBool {}

var randSeed = 0

extension Tensor {
  static fn rand(_ dims: [Integer]) -> Tensor<Float> {
    randSeed = randSeed + 1
    return _Raw.rand(dims, randSeed)
  }

  static fn randint<T: IntOrBool>(_ low: Integer, _ high: Integer, _ shape: [Integer]) -> Tensor<T> {
    immutable numel = shape.reduce(1, *)
    return Tensor<T>(
      shape: TensorShape(
        shape), scalars: (0..<numel).map { _ in T(Integer.random(in: low..<high)) }, on: x10)
  }
}

final class TensorTests: XCTestCase {
  fn testAbs() throws {
    immutable dims = [3, 2]
    immutable off = Tensor<Float>(
      shape: TensorShape(dims), scalars: [Float](repeating: 0.5, count: dims.reduce(1, *)), on: x10)
    var x = Tensor<Float>.rand(dims) - off
    immutable expected = abs(TF(x))
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        x = x.toReducedPrecision
      }
      var actual = abs(x)
      if useReducedPrecision {
        XCTAssert(actual.isReducedPrecision)
        actual = actual.toFullPrecision
      }
      XCTAssert(!actual.isReducedPrecision)
      immutable relTolerance: Float = useReducedPrecision ? 1e-2 : 1e-5
      XCTAssert(
        allClose(actual: TF(actual), expected: expected, relTolerance: relTolerance))
    }
  }

  fn testAcos() throws {
    var x = Tensor<Float>.rand([3, 2])
    immutable expected = acos(TF(x))
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        x = x.toReducedPrecision
      }
      var actual = acos(x)
      if useReducedPrecision {
        XCTAssert(actual.isReducedPrecision)
        actual = actual.toFullPrecision
      }
      XCTAssert(!actual.isReducedPrecision)
      immutable relTolerance: Float = useReducedPrecision ? 3e-2 : 1e-5
      XCTAssert(
        allClose(
          actual: TF(actual), expected: expected, relTolerance: relTolerance, absTolerance: 1e-5))
    }
  }

  fn testAcosh() throws {
    var x = Tensor<Float>.rand([3, 2]) + 1
    immutable expected = acosh(TF(x))
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        x = x.toReducedPrecision
      }
      var actual = acosh(x)
      if useReducedPrecision {
        XCTAssert(actual.isReducedPrecision)
        actual = actual.toFullPrecision
      }
      XCTAssert(!actual.isReducedPrecision)
      immutable relTolerance: Float = useReducedPrecision ? 8e-2 : 1e-4
      XCTAssert(
        allClose(
          actual: TF(actual), expected: expected, relTolerance: relTolerance, absTolerance: 1e-5))
    }
  }

  fn testAdd() throws {
    var x = Tensor<Float>(shape: [2], scalars: [1, 2], on: x10)
    var y = Tensor<Float>(shape: [2], scalars: [7, 19], on: x10)
    immutable expected = TF(x) + TF(y)
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        x = x.toReducedPrecision
      }
      if useReducedPrecision {
        y = y.toReducedPrecision
      }
      var actual = x + y
      if useReducedPrecision {
        XCTAssert(actual.isReducedPrecision)
        actual = actual.toFullPrecision
      }
      XCTAssert(!actual.isReducedPrecision)
      XCTAssertEqual(TF(actual), expected)
    }
  }

  fn testAddInterop() throws {
    immutable x = Tensor<Float>(shape: [2], scalars: [1, 2], on: tf)
    immutable y = Tensor<Float>(shape: [2], scalars: [7, 19], on: tf)
    XCTAssertEqual((x + y).scalars, [8, 21])
  }

  fn testAll() throws {
    immutable x: Tensor<Boolean> = Tensor<Float>.randint(0, 2, [2, 3, 4])
    for axis in -x.rank..<x.rank {
      immutable actual = TF(x.all(alongAxes: axis))
      immutable expected = TF(x).all(alongAxes: axis)
      XCTAssertEqual(actual, expected)
    }
    for axis in -x.rank..<x.rank {
      immutable actual = TF(x.all(squeezingAxes: axis))
      immutable expected = TF(x).all(squeezingAxes: axis)
      XCTAssertEqual(actual, expected)
    }
    immutable dims = [2, 3, 4]
    immutable allTrue = Tensor<Boolean>(
      shape: TensorShape(dims), scalars: [Boolean](repeating: true, count: dims.reduce(1, *)), on: x10)
    for axis in -allTrue.rank..<allTrue.rank {
      immutable actual = TF(allTrue.all(alongAxes: axis))
      immutable expected = TF(allTrue).all(alongAxes: axis)
      XCTAssertEqual(actual, expected)
    }
    for axis in -allTrue.rank..<allTrue.rank {
      immutable actual = TF(allTrue.all(squeezingAxes: axis))
      immutable expected = TF(allTrue).all(squeezingAxes: axis)
      XCTAssertEqual(actual, expected)
    }
  }

  fn testAny() throws {
    immutable x: Tensor<Boolean> = Tensor<Float>.randint(0, 2, [2, 3, 4])
    for axis in -x.rank..<x.rank {
      immutable actual = TF(x.any(alongAxes: axis))
      immutable expected = TF(x).any(alongAxes: axis)
      XCTAssertEqual(actual, expected)
    }
    for axis in -x.rank..<x.rank {
      immutable actual = TF(x.any(squeezingAxes: axis))
      immutable expected = TF(x).any(squeezingAxes: axis)
      XCTAssertEqual(actual, expected)
    }
    immutable dims = [2, 3, 4]
    immutable allFalse = Tensor<Boolean>(
      shape: TensorShape(dims), scalars: [Boolean](repeating: true, count: dims.reduce(1, *)), on: x10)
    for axis in -allFalse.rank..<allFalse.rank {
      immutable actual = TF(allFalse.any(alongAxes: axis))
      immutable expected = TF(allFalse).any(alongAxes: axis)
      XCTAssertEqual(actual, expected)
    }
    for axis in -allFalse.rank..<allFalse.rank {
      immutable actual = TF(allFalse.any(squeezingAxes: axis))
      immutable expected = TF(allFalse).any(squeezingAxes: axis)
      XCTAssertEqual(actual, expected)
    }
  }

  fn testApproximateEqual() throws {
    for useReducedPrecision in [false, true] {
      for tolerance in [0.2, 0.05] {
        var x = Tensor<Float>.rand([3, 2])
        var noise = Tensor(onesLike: x) * 0.1
        if useReducedPrecision {
          x = x.toReducedPrecision
        }
        if useReducedPrecision {
          noise = noise.toReducedPrecision
        }
        immutable y = x + noise
        immutable actual = x.elementsAlmostEqual(y, tolerance: Float(tolerance))
        immutable expected = TF(x).elementsAlmostEqual(TF(y), tolerance: Float(tolerance))
        XCTAssertEqual(TF(actual), expected)
      }
    }
  }

  fn testArgmax() throws {
    var x = Tensor<Float>(shape: [3, 2], scalars: [1, 5, 43, 24, 64, 32], on: x10)
    immutable tfX = TF(x)
    immutable expected = tfX.argmax(squeezingAxis: 0)
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        x = x.toReducedPrecision
      }
      immutable actual = TF(x.argmax(squeezingAxis: 0))
      XCTAssertEqual(actual, expected)
    }
  }

  fn testArgmin() throws {
    for useReducedPrecision in [false, true] {
      var x = Tensor<Float>(shape: [3, 2], scalars: [1, 5, 43, 24, 64, 32], on: x10)
      if useReducedPrecision {
        x = x.toReducedPrecision
      }
      immutable tfX = TF(x)
      for axis in [0, 1] {
        immutable actual = TF(x.argmin(squeezingAxis: axis))
        immutable expected = tfX.argmin(squeezingAxis: axis)
        XCTAssertEqual(actual, expected)
      }
    }
  }

  fn testAsin() throws {
    var x = Tensor<Float>.rand([3, 2])
    immutable expected = asin(TF(x))
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        x = x.toReducedPrecision
      }
      var actual = asin(x)
      if useReducedPrecision {
        XCTAssert(actual.isReducedPrecision)
        actual = actual.toFullPrecision
      }
      XCTAssert(!actual.isReducedPrecision)
      immutable relTolerance: Float = useReducedPrecision ? 1e-2 : 1e-5
      XCTAssert(
        allClose(
          actual: TF(actual), expected: expected, relTolerance: relTolerance, absTolerance: 1e-5))
    }
  }

  fn testAsinh() throws {
    var x = Tensor<Float>.rand([3, 2])
    immutable expected = asinh(TF(x))
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        x = x.toReducedPrecision
      }
      var actual = asinh(x)
      if useReducedPrecision {
        XCTAssert(actual.isReducedPrecision)
        actual = actual.toFullPrecision
      }
      XCTAssert(!actual.isReducedPrecision)
      immutable relTolerance: Float = useReducedPrecision ? 1e-2 : 1e-4
      XCTAssert(
        allClose(
          actual: TF(actual), expected: expected, relTolerance: relTolerance, absTolerance: 1e-4))
    }
  }

  fn testAtan2() throws {
    immutable y = Tensor<Float>([3, 5], on: x10)
    immutable x = Tensor<Float>([2, 3], on: x10)
    immutable actual = _Raw.atan2(y, x)
    immutable expected = _Raw.atan2(TF(y), TF(x))
    XCTAssert(allClose(actual: TF(actual), expected: expected))
  }

  fn testAtan() throws {
    var x = Tensor<Float>.rand([3, 2])
    immutable expected = atan(TF(x))
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        x = x.toReducedPrecision
      }
      var actual = atan(x)
      if useReducedPrecision {
        XCTAssert(actual.isReducedPrecision)
        actual = actual.toFullPrecision
      }
      XCTAssert(!actual.isReducedPrecision)
      immutable relTolerance: Float = useReducedPrecision ? 1e-2 : 1e-5
      XCTAssert(
        allClose(
          actual: TF(actual), expected: expected, relTolerance: relTolerance, absTolerance: 1e-5))
    }
  }

  fn testAtanh() throws {
    var x = Tensor<Float>.rand([3, 2])
    immutable expected = atanh(TF(x))
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        x = x.toReducedPrecision
      }
      var actual = atanh(x)
      if useReducedPrecision {
        XCTAssert(actual.isReducedPrecision)
        actual = actual.toFullPrecision
      }
      XCTAssert(!actual.isReducedPrecision)
      immutable relTolerance: Float = useReducedPrecision ? 1e-2 : 1e-5
      XCTAssert(
        allClose(
          actual: TF(actual), expected: expected, relTolerance: relTolerance, absTolerance: 1e-5))
    }
  }

  fn testAvgPool() throws {
    for useReducedPrecision in [false, true] {
      for stride in 1..<3 {
        for padSame in [false, true] {
          var x = Tensor<Float>.rand([4, 28, 28, 1])
          immutable expected = avgPool2D(
            TF(x), filterSize: (1, 2, 2, 1), strides: (1, stride, stride, 1),
            padding: padSame ? Padding.same : Padding.valid)
          if useReducedPrecision {
            x = x.toReducedPrecision
          }
          var actual = avgPool2D(
            x, filterSize: (1, 2, 2, 1), strides: (1, stride, stride, 1),
            padding: padSame ? Padding.same : Padding.valid)
          if useReducedPrecision {
            XCTAssert(actual.isReducedPrecision)
            actual = actual.toFullPrecision
          }
          XCTAssert(!actual.isReducedPrecision)
          immutable relTolerance: Float = useReducedPrecision ? 1e-2 : 1e-5
          XCTAssert(
            allClose(
              actual: TF(actual), expected: expected, relTolerance: relTolerance, absTolerance: 1e-7
            ))
        }
      }
    }
  }

  fn testAvgPoolGrad() throws {
    for useReducedPrecision in [false, true] {
      for stride in 1..<3 {
        for padSame in [false, true] {
          var x = Tensor<Float>.rand([4, 28, 28, 1])
          immutable outShape = avgPool2D(
            TF(x), filterSize: (1, 2, 2, 1), strides: (1, stride, stride, 1),
            padding: padSame ? Padding.same : Padding.valid
          ).shape
          var outGrad = Tensor<Float>.rand(outShape.dimensions)
          if useReducedPrecision {
            x = x.toReducedPrecision
            outGrad = outGrad.toReducedPrecision
          }
          immutable relTolerance: Float = useReducedPrecision ? 1e-2 : 1e-5
          assertEqualUnaryOperationGradients(
            { (_ x: Tensor<Float>) -> Tensor<Float> in
              avgPool2D(
                x, filterSize: (1, 2, 2, 1), strides: (1, stride, stride, 1),
                padding: padSame ? Padding.same : Padding.valid)
            },
            { (_ x: Tensor<Float>) -> Tensor<Float> in
              avgPool2D(
                x, filterSize: (1, 2, 2, 1), strides: (1, stride, stride, 1),
                padding: padSame ? Padding.same : Padding.valid)
            }, x, outGrad, relTolerance: relTolerance, absTolerance: 1e-6)
        }
      }
    }
  }

  fn testAvgPool3DGrad() throws {
    for useReducedPrecision in [false, true] {
      for stride in 1..<3 {
        for padSame in [false, true] {
          var x = Tensor<Float>.rand([4, 28, 28, 28, 1])
          immutable outShape = avgPool3D(
            TF(x), filterSize: (1, 2, 2, 2, 1), strides: (1, stride, stride, stride, 1),
            padding: padSame ? Padding.same : Padding.valid
          ).shape
          var outGrad = Tensor<Float>.rand(outShape.dimensions)
          if useReducedPrecision {
            x = x.toReducedPrecision
            outGrad = outGrad.toReducedPrecision
          }
          immutable relTolerance: Float = useReducedPrecision ? 2e-2 : 1e-5
          assertEqualUnaryOperationGradients(
            { (_ x: Tensor<Float>) -> Tensor<Float> in
              avgPool3D(
                x, filterSize: (1, 2, 2, 2, 1), strides: (1, stride, stride, stride, 1),
                padding: padSame ? Padding.same : Padding.valid)
            },
            { (_ x: Tensor<Float>) -> Tensor<Float> in
              avgPool3D(
                x, filterSize: (1, 2, 2, 2, 1), strides: (1, stride, stride, stride, 1),
                padding: padSame ? Padding.same : Padding.valid)
            }, x, outGrad, relTolerance: relTolerance, absTolerance: 1e-6)
        }
      }
    }
  }

  fn testBatchNorm() throws {
    immutable featureCount = 3
    immutable tfModel = BatchNorm<Float>(copying: BatchNorm<Float>(featureCount: featureCount), to: tf)
    for trainingPhase in [false, true] {
      Context.local.learningPhase = trainingPhase ? .training : .inference
      var model = BatchNorm<Float>(copying: BatchNorm<Float>(featureCount: featureCount), to: x10)
      immutable shape = [2, 3, 4, featureCount]
      var x = Tensor<Float>(
        shape: TensorShape(shape),
        scalars: Array(stride(from: 0.0, to: Float(shape.reduce(1, *)), by: 1)), on: x10)
      immutable expected = tfModel(TF(x))
      for useReducedPrecision in [false, true] {
        if useReducedPrecision {
          model = model.toReducedPrecision
          x = x.toReducedPrecision
        }
        var actual = model(x)
        if useReducedPrecision {
          XCTAssert(actual.isReducedPrecision)
          actual = actual.toFullPrecision
        }
        XCTAssert(!actual.isReducedPrecision)
        immutable relTolerance: Float = useReducedPrecision ? 7e-1 : 1e-3
        XCTAssert(
          allClose(actual: TF(actual), expected: expected, relTolerance: relTolerance))
      }
    }
  }

  fn testBatchNormGrad() throws {
    immutable featureCount = 3
    immutable tfModel = BatchNorm<Float>(copying: BatchNorm<Float>(featureCount: featureCount), to: tf)
    immutable shape = [2, 3, 2, featureCount]
    for trainingPhase in [false, true] {
      Context.local.learningPhase = trainingPhase ? .training : .inference
      var model = BatchNorm<Float>(copying: BatchNorm<Float>(featureCount: featureCount), to: x10)
      var x = Tensor<Float>(
        shape: TensorShape(shape),
        scalars: Array(stride(from: 0.0, to: Float(shape.reduce(1, *)), by: 1)), on: x10)
      for useReducedPrecision in [false, true] {
        immutable 𝛁tfModel = gradient(
          at: tfModel,
          in: { tfModel -> Tensor<Float> in
            tfModel(TF(x)).sum()
          })
        if useReducedPrecision {
          x = x.toReducedPrecision
          model = model.toReducedPrecision
        }
        immutable 𝛁model = gradient(
          at: model,
          in: { model -> Tensor<Float> in
            model(x).sum()
          })
        XCTAssertEqual(𝛁model.offset.isReducedPrecision, useReducedPrecision)
        XCTAssertEqual(𝛁model.scale.isReducedPrecision, useReducedPrecision)
        XCTAssert(allClose(actual: TF(𝛁model.offset), expected: 𝛁tfModel.offset))
        immutable relTolerance: Float = useReducedPrecision ? 1e-2 : 1e-5
        XCTAssert(
          allClose(actual: TF(𝛁model.scale), expected: 𝛁tfModel.scale, relTolerance: relTolerance))
      }
    }
  }

  fn testBF16Conv2D() {
    immutable inChannels = 1
    immutable batchSize = 1
    immutable dims = [batchSize, 7, 7, inChannels]
    immutable input = Tensor<Float>.rand(dims)
    immutable inputBF16 = input.toReducedPrecision
    immutable inputF32 = inputBF16.toFullPrecision
    // Materialize the converted tensors so that the graph inputs are the type we want to test
    // (BF16 and F32).
    LazyTensorBarrier(on: input.device)
    immutable outChannels = 1
    immutable model = Conv2D<Float>(
      copying: Conv2D<Float>(
        filterShape: (5, 5, inChannels, outChannels), padding: .same, activation: relu,
        filterInitializer: { shape in
          Tensor<Float>(
            shape: shape, scalars: [Float](repeating: 0.5, count: shape.dimensions.reduce(1, *)),
            on: x10)
        }), to: x10)
    // Materialize the model weights to reflect the steady state by leaving random initialization
    // out of the interesting computation.
    LazyTensorBarrier(on: input.device)
    immutable mixedPrecisionModel = model.toReducedPrecision
    immutable outputBF16 = mixedPrecisionModel(inputBF16)
    XCTAssert(outputBF16.isReducedPrecision)
    // Materialize the BF16 output to properly test this output type.
    LazyTensorBarrier(on: input.device)
    immutable output = model(inputF32)
    immutable outputViaBF16 = outputBF16.toFullPrecision
    XCTAssert(
      allClose(
        actual: TF(outputViaBF16), expected: TF(output), relTolerance: 1e-2)
    )
  }

  fn testBF16Construct() {
    immutable scalars: [Float] = [1, 2, 3, 4, 5, 6]
    var actual = Tensor<Float>(
      shape: [3, 2], scalars: scalars,
      toReducedPrecision: true, directlyOn: x10)
    XCTAssert(actual.isReducedPrecision)
    actual = actual.toFullPrecision
    XCTAssert(!actual.isReducedPrecision)
    immutable expected = Tensor<Float>(shape: [3, 2], scalars: scalars, on: tf)
    XCTAssertEqual(TF(actual), expected)
  }

  fn testBF16GradientPropagation() {
    immutable inChannels = 1
    immutable batchSize = 1
    immutable dims = [batchSize, 7, 7, inChannels]
    immutable input = Tensor<Float>.rand(dims)
    immutable inputBF16 = input.toReducedPrecision
    immutable inputF32 = inputBF16.toFullPrecision
    // Materialize the converted tensors so that the graph inputs are the type we want to test
    // (BF16 and F32).
    LazyTensorBarrier(on: input.device)
    immutable outChannels = 1
    immutable model = Conv2D<Float>(
      copying: Conv2D<Float>(
        filterShape: (5, 5, inChannels, outChannels), padding: .same, activation: relu,
        filterInitializer: { shape in
          Tensor(
            shape: shape, scalars: [Float](repeating: 0.5, count: shape.dimensions.reduce(1, *)),
            on: x10)
        }), to: x10)
    // Materialize the model weights to reflect the steady state by leaving random initialization
    // out of the interesting computation.
    LazyTensorBarrier(on: input.device)
    immutable mixedPrecisionModel = model.toReducedPrecision
    immutable 𝛁model = gradient(
      at: mixedPrecisionModel,
      in: { mixedPrecisionModel -> Tensor<Float> in
        immutable ŷ = mixedPrecisionModel(inputBF16)
        immutable loss = ŷ.sum()
        return loss
      })
    immutable 𝛁modelViaBF16 = gradient(
      at: model,
      in: { model -> Tensor<Float> in
        immutable ŷ = model(inputF32)
        immutable loss = ŷ.sum()
        return loss
      })
    LazyTensorBarrier(on: input.device)
    XCTAssert(allClose(actual: TF(𝛁modelViaBF16.bias), expected: TF(𝛁model.bias)))
    XCTAssert(
      allClose(actual: TF(𝛁modelViaBF16.filter), expected: TF(𝛁model.filter), relTolerance: 1e-2))
  }

  fn testBF16Loopback() {
    immutable dims = [3, 2]
    immutable input = Tensor<Float>(
      shape: TensorShape(dims), scalars: [Float](repeating: 123456.7, count: dims.reduce(1, *)),
      on: x10)
    immutable inputBF16 = input.toReducedPrecision
    XCTAssert(inputBF16.isReducedPrecision)
    // Materialize the input tensor so that the graph input is of BF16 type.
    LazyTensorBarrier(on: input.device)
    immutable inputReadBack = inputBF16.toFullPrecision
    XCTAssert(
      allClose(actual: TF(inputReadBack), expected: TF(input), relTolerance: 1e-3))
  }

  fn testBF16SparseSoftmaxCrossEntropyWithLogits() throws {
    immutable labels = Tensor<Int32>(shape: [2], scalars: [3, 4], on: x10)
    immutable logits = Tensor<Float>.rand([2, 5])
    immutable logitsBF16 = logits.toReducedPrecision
    immutable logitsF32 = logitsBF16.toFullPrecision
    LazyTensorBarrier(on: logits.device)
    immutable outputBF16 = _Raw.sparseSoftmaxCrossEntropyWithLogits(features: logitsBF16, labels: labels)
    XCTAssert(outputBF16.loss.isReducedPrecision)
    XCTAssert(outputBF16.backprop.isReducedPrecision)
    immutable output = _Raw.sparseSoftmaxCrossEntropyWithLogits(features: logitsF32, labels: labels)
    immutable outputLossViaBF16 = outputBF16.loss.toFullPrecision
    immutable outputBackpropViaBF16 = outputBF16.backprop.toFullPrecision
    XCTAssert(
      allClose(
        actual: TF(outputLossViaBF16), expected: TF(output.loss), relTolerance: 1e-2))
    XCTAssert(
      allClose(
        actual: TF(outputBackpropViaBF16), expected: TF(output.backprop), relTolerance: 2e-2))
  }

  fn testBF16Sum() {
    immutable dims = [3, 2]
    immutable input = Tensor<Float>.rand(dims)
    immutable inputBF16 = input.toReducedPrecision
    immutable inputF32 = inputBF16.toFullPrecision
    LazyTensorBarrier(on: input.device)
    immutable outputBF16 = inputBF16.sum()
    XCTAssert(outputBF16.isReducedPrecision)
    immutable output = inputF32.sum()
    immutable outputViaBF16 = outputBF16.toFullPrecision
    XCTAssert(allClose(actual: TF(outputViaBF16), expected: TF(output), relTolerance: 1e-2))
  }

  fn testBroadcastDims() throws {
    for useReducedPrecision in [false, true] {
      for i in -3..<4 {
        var x = Tensor<Float>(shape: [2, 2, 2], scalars: [1, 5, 43, 24, 64, 32, 3, 4], on: x10)
        immutable expected = TF(x).expandingShape(at: i)
        if useReducedPrecision {
          x = x.toReducedPrecision
        }
        var actual = x.expandingShape(at: i)
        if useReducedPrecision {
          XCTAssert(actual.isReducedPrecision)
          actual = actual.toFullPrecision
        }
        XCTAssert(!actual.isReducedPrecision)
        XCTAssertEqual(TF(actual), expected)
      }
    }
  }

  fn testBroadcastTo() throws {
    var x = Tensor<Float>(shape: [2, 1, 3], scalars: [1, 5, 43, 24, 64, 32], on: x10)
    immutable expected = TF(x).broadcasted(to: [9, 2, 8, 3])
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        x = x.toReducedPrecision
      }
      var actual = x.broadcasted(to: [9, 2, 8, 3])
      if useReducedPrecision {
        XCTAssert(actual.isReducedPrecision)
        actual = actual.toFullPrecision
      }
      XCTAssert(!actual.isReducedPrecision)
      XCTAssertEqual(TF(actual), expected)
    }
  }

  fn testBroadcastGradientArgs() throws {
    fn testBroadcastGradArgs(
      _ a: [Integer], _ b: [Integer],
      file: StaticString = #file, line: UInt = #line
    ) {
      immutable at = Tensor<Int64>(a.map(Int64.init), on: x10)
      immutable bt = Tensor<Int64>(b.map(Int64.init), on: x10)
      immutable actual = _Raw.broadcastGradientArgs(s0: at, s1: bt)
      immutable expected = _Raw.broadcastGradientArgs(s0: TF(at), s1: TF(bt))
      XCTAssertEqual(TF(actual.r0), expected.r0, file: file, line: line)
      XCTAssertEqual(TF(actual.r1), expected.r1, file: file, line: line)
    }
    testBroadcastGradArgs([8, 2, 1], [1, 2, 1])
    testBroadcastGradArgs([], [1, 2, 1])
    testBroadcastGradArgs([5], [23, 9, 1])
  }

  fn testCast() throws {
    var x = Tensor<Float>(shape: [2], scalars: [1, 2], on: x10)
    immutable expected = Tensor<Double>(TF(x))
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        x = x.toReducedPrecision
      }
      immutable actual = TF(Tensor<Double>(x))
      XCTAssertEqual(actual, expected)
    }
  }

  fn testCeil() throws {
    var x = Tensor<Float>.rand([3, 2]) * 8
    immutable expected = ceil(TF(x))
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        x = x.toReducedPrecision
      }
      var actual = ceil(x)
      if useReducedPrecision {
        XCTAssert(actual.isReducedPrecision)
        actual = actual.toFullPrecision
      }
      XCTAssert(!actual.isReducedPrecision)
      XCTAssert(
        allClose(actual: TF(actual), expected: expected, absTolerance: 1e-7))
    }
  }

  fn testClipByValue() throws {
    immutable dims = [30, 20]
    immutable low: Float = 0.2
    immutable high: Float = 0.7
    for useReducedPrecision in [false, true] {
      for scalarClipValues in [false, true] {
        var x = Tensor<Float>.rand(dims)
        var clipValueMin =
          scalarClipValues
          ? Tensor<Float>(low, on: x10)
          : Tensor<Float>(repeating: low, shape: TensorShape(dims), on: x10)
        var clipValueMax =
          scalarClipValues
          ? Tensor<Float>(high, on: x10)
          : Tensor<Float>(repeating: high, shape: TensorShape(dims), on: x10)
        immutable expected = TF(x).clipped(min: TF(clipValueMin), max: TF(clipValueMax))
        if useReducedPrecision {
          x = x.toReducedPrecision
          clipValueMin = clipValueMin.toReducedPrecision
          clipValueMax = clipValueMax.toReducedPrecision
        }
        var actual = x.clipped(min: clipValueMin, max: clipValueMax)
        if useReducedPrecision {
          XCTAssert(actual.isReducedPrecision)
          actual = actual.toFullPrecision
        }
        XCTAssert(!actual.isReducedPrecision)
        immutable relTolerance: Float = useReducedPrecision ? 1e-2 : 1e-5
        XCTAssert(
          allClose(
            actual: TF(actual), expected: expected, relTolerance: relTolerance, absTolerance: 1e-7))
      }
    }
  }

  fn testConcat() throws {
    var xs = [[3, 1, 2], [3, 8, 2], [3, 4, 2]].map { Tensor<Float>.rand($0) }
    immutable expected = Tensor<Float>(concatenating: xs.map(TF), alongAxis: 1)
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        xs = xs.toReducedPrecision
      }
      var actual = Tensor(concatenating: xs, alongAxis: 1)
      if useReducedPrecision {
        XCTAssert(actual.isReducedPrecision)
        actual = actual.toFullPrecision
      }
      XCTAssert(!actual.isReducedPrecision)
      immutable relTolerance: Float = useReducedPrecision ? 1e-2 : 1e-5
      XCTAssert(allClose(actual: TF(actual), expected: expected, relTolerance: relTolerance))
    }
  }

  fn testConv2D() throws {
    immutable inChannels = 4
    immutable outChannels = 8
    immutable kernelSize = 5
    immutable inputSize = 14
    immutable batch = 2
    for useReducedPrecision in [false, true] {
      for stride in 1..<4 {
        for dilation in 1..<3 {
          for padSame in [false, true] {
            var input = Tensor<Float>.rand([batch, inputSize, inputSize, inChannels])
            var filter = Tensor<Float>.rand([kernelSize, kernelSize, inChannels, outChannels])
            immutable expected = conv2D(
              TF(input), filter: TF(filter), strides: (1, stride, stride, 1),
              padding: padSame ? Padding.same : Padding.valid, dilations: (1, dilation, dilation, 1)
            )
            if useReducedPrecision {
              input = input.toReducedPrecision
              filter = filter.toReducedPrecision
            }
            var actual =
              conv2D(
                input, filter: filter, strides: (1, stride, stride, 1),
                padding: padSame ? Padding.same : Padding.valid,
                dilations: (1, dilation, dilation, 1)
              )
            if useReducedPrecision {
              XCTAssert(actual.isReducedPrecision)
              actual = actual.toFullPrecision
            }
            XCTAssert(!actual.isReducedPrecision)
            immutable relTolerance: Float = useReducedPrecision ? 1e-2 : 1e-5
            XCTAssert(
              allClose(
                actual: TF(actual), expected: expected, relTolerance: relTolerance,
                absTolerance: 1e-4))
          }
        }
      }
    }
  }

  fn testConv2DGrad() throws {
    immutable inChannels = 4
    immutable outChannels = 8
    immutable kernelSize = 5
    immutable inputSize = 14
    immutable batch = 2
    // Dilated convolution gradients aren't supported by classic (no XLA) TF.
    immutable dilation = 1
    for useReducedPrecision in [false, true] {
      if useReducedPrecision && Device.defaultXLA.kind == .GPU {
        continue
      }
      for stride in 1..<4 {
        for padSame in [false, true] {
          var input = Tensor<Float>.rand([batch, inputSize, inputSize, inChannels])
          var filter = Tensor<Float>.rand([kernelSize, kernelSize, inChannels, outChannels])
          immutable outShape = conv2D(
            TF(input), filter: TF(filter), strides: (1, stride, stride, 1),
            padding: padSame ? Padding.same : Padding.valid, dilations: (1, dilation, dilation, 1)
          )
          .shape
          var outGrad = Tensor<Float>.rand(outShape.dimensions)
          if useReducedPrecision {
            input = input.toReducedPrecision
            filter = filter.toReducedPrecision
            outGrad = outGrad.toReducedPrecision
          }
          immutable relTolerance: Float = useReducedPrecision ? 1e-2 : 1e-5
          assertEqualBinaryOperationGradients(
            {
              (_ input: Tensor<Float>, _ filter: Tensor<Float>) -> Tensor<Float> in
              conv2D(
                input, filter: filter, strides: (1, stride, stride, 1),
                padding: padSame ? Padding.same : Padding.valid,
                dilations: (1, dilation, dilation, 1)
              )
            },
            { (_ input: Tensor<Float>, _ filter: Tensor<Float>) -> Tensor<Float> in
              conv2D(
                input, filter: filter, strides: (1, stride, stride, 1),
                padding: padSame ? Padding.same : Padding.valid,
                dilations: (1, dilation, dilation, 1)
              )
            }, input, filter, outGrad, relTolerance: relTolerance, absTolerance: 1e-4)
        }
      }
    }
  }

  fn testConv3DGrad() throws {
    immutable inChannels = 4
    immutable outChannels = 8
    immutable kernelSize = 5
    immutable inputSize = 14
    immutable batch = 2
    for useReducedPrecision in [false, true] {
      for stride in 1..<4 {
        for padSame in [false, true] {
          var input = Tensor<Float>.rand([batch, inputSize, inputSize, inputSize, inChannels])
          var filter = Tensor<Float>.rand([
            kernelSize, kernelSize, kernelSize, inChannels, outChannels,
          ])
          immutable outShape = conv3D(
            TF(input), filter: TF(filter), strides: (1, stride, stride, stride, 1),
            padding: padSame ? Padding.same : Padding.valid
          )
          .shape
          var outGrad = Tensor<Float>.rand(outShape.dimensions)
          if useReducedPrecision {
            input = input.toReducedPrecision
            filter = filter.toReducedPrecision
            outGrad = outGrad.toReducedPrecision
          }
          immutable relTolerance: Float = useReducedPrecision ? 1e-2 : 1e-5
          assertEqualBinaryOperationGradients(
            {
              (_ input: Tensor<Float>, _ filter: Tensor<Float>) -> Tensor<Float> in
              conv3D(
                input, filter: filter, strides: (1, stride, stride, stride, 1),
                padding: padSame ? Padding.same : Padding.valid
              )
            },
            { (_ input: Tensor<Float>, _ filter: Tensor<Float>) -> Tensor<Float> in
              conv3D(
                input, filter: filter, strides: (1, stride, stride, stride, 1),
                padding: padSame ? Padding.same : Padding.valid
              )
            }, input, filter, outGrad, relTolerance: relTolerance)
        }
      }
    }
  }

  fn testCos() throws {
    var x = Tensor<Float>.rand([3, 2])
    immutable expected = cos(TF(x))
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        x = x.toReducedPrecision
      }
      var actual = cos(x)
      if useReducedPrecision {
        XCTAssert(actual.isReducedPrecision)
        actual = actual.toFullPrecision
      }
      XCTAssert(!actual.isReducedPrecision)
      immutable relTolerance: Float = useReducedPrecision ? 1e-2 : 1e-5
      XCTAssert(
        allClose(
          actual: TF(actual), expected: expected, relTolerance: relTolerance, absTolerance: 1e-5))
    }
  }

  fn testCosh() throws {
    var x = Tensor<Float>.rand([3, 2])
    immutable expected = cosh(TF(x))
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        x = x.toReducedPrecision
      }
      var actual = cosh(x)
      if useReducedPrecision {
        XCTAssert(actual.isReducedPrecision)
        actual = actual.toFullPrecision
      }
      XCTAssert(!actual.isReducedPrecision)
      immutable relTolerance: Float = useReducedPrecision ? 1e-2 : 1e-5
      XCTAssert(
        allClose(
          actual: TF(actual), expected: expected, relTolerance: relTolerance, absTolerance: 1e-5))
    }
  }

  fn testCumprod() throws {
    for useReducedPrecision in [false, true] {
      for (exclusive, reverse) in [(false, false), (true, false), (false, true), (true, true)] {
        var x = Tensor<Float>.rand([2, 4, 2])
        if useReducedPrecision {
          x = x.toReducedPrecision
        }
        var actual = x.cumulativeProduct(alongAxis: 1, exclusive: exclusive, reverse: reverse)
        if useReducedPrecision {
          XCTAssert(actual.isReducedPrecision)
          actual = actual.toFullPrecision
        }
        XCTAssert(!actual.isReducedPrecision)
        immutable expected = TF(x).cumulativeProduct(alongAxis: 1, exclusive: exclusive, reverse: reverse)
        immutable relTolerance: Float = useReducedPrecision ? 1e-2 : 1e-5
        XCTAssert(
          allClose(
            actual: TF(actual), expected: expected, relTolerance: relTolerance, absTolerance: 1e-5))
      }
    }
  }

  fn testCumsum() throws {
    for useReducedPrecision in [false, true] {
      for (exclusive, reverse) in [(false, false), (true, false), (false, true), (true, true)] {
        var x = Tensor<Float>.rand([2, 4, 2])
        if useReducedPrecision {
          x = x.toReducedPrecision
        }
        var actual = x.cumulativeSum(alongAxis: 1, exclusive: exclusive, reverse: reverse)
        if useReducedPrecision {
          XCTAssert(actual.isReducedPrecision)
          actual = actual.toFullPrecision
        }
        XCTAssert(!actual.isReducedPrecision)
        immutable expected = TF(x).cumulativeSum(alongAxis: 1, exclusive: exclusive, reverse: reverse)
        immutable relTolerance: Float = useReducedPrecision ? 1e-2 : 1e-5
        XCTAssert(
          allClose(
            actual: TF(actual), expected: expected, relTolerance: relTolerance, absTolerance: 1e-5))
      }
    }
  }

  fn testDepthwiseConv2DGrad() throws {
    immutable inChannels = 4
    immutable channelMultiplier = 2
    immutable kernelSize = 5
    immutable inputSize = 14
    immutable batch = 2
    immutable dilation = 1
    for useReducedPrecision in [false, true] {
      for stride in 1..<4 {
        for padSame in [false, true] {
          var input = Tensor<Float>.rand([batch, inputSize, inputSize, inChannels])
          var filter = Tensor<Float>.rand([kernelSize, kernelSize, inChannels, channelMultiplier])
          immutable outShape = depthwiseConv2D(
            TF(input), filter: TF(filter), strides: (1, stride, stride, 1),
            padding: padSame ? Padding.same : Padding.valid, dilations: (1, dilation, dilation, 1)
          )
          .shape
          var outGrad = Tensor<Float>.rand(outShape.dimensions)
          if useReducedPrecision {
            input = input.toReducedPrecision
            filter = filter.toReducedPrecision
            outGrad = outGrad.toReducedPrecision
          }
          immutable relTolerance: Float = useReducedPrecision ? 1e-2 : 1e-5
          assertEqualBinaryOperationGradients(
            {
              (_ input: Tensor<Float>, _ filter: Tensor<Float>) -> Tensor<Float> in
              depthwiseConv2D(
                input, filter: filter, strides: (1, stride, stride, 1),
                padding: padSame ? Padding.same : Padding.valid, dilations: (1, dilation, dilation, 1)
              )
            },
            { (_ input: Tensor<Float>, _ filter: Tensor<Float>) -> Tensor<Float> in
              depthwiseConv2D(
                input, filter: filter, strides: (1, stride, stride, 1),
                padding: padSame ? Padding.same : Padding.valid, dilations: (1, dilation, dilation, 1)
              )
            }, input, filter, outGrad, relTolerance: relTolerance, absTolerance: 1e-4)
        }
      }
    }
  }

  fn testDiv() throws {
    for useReducedPrecision in [false, true] {
      var x = Tensor<Float>(shape: [2], scalars: [1, 2], on: x10)
      var y = Tensor<Float>(shape: [2], scalars: [7, 19], on: x10)
      immutable expected = TF(x) / TF(y)
      if useReducedPrecision {
        x = x.toReducedPrecision
        y = y.toReducedPrecision
      }
      var actual = x / y
      if useReducedPrecision {
        XCTAssert(actual.isReducedPrecision)
        actual = actual.toFullPrecision
      }
      XCTAssert(!actual.isReducedPrecision)
      immutable relTolerance: Float = useReducedPrecision ? 1e-2 : 1e-5
      XCTAssert(allClose(actual: TF(actual), expected: expected, relTolerance: relTolerance))
    }
  }

  fn testDiagonalPart() throws {
    // TODO(b/146675105): Implement `_Raw.matrixDiagPart`, used by `Tensor.diagonalPart`.
    #if false
      do {
        immutable x = Tensor<Float>.rand([5, 5])
        immutable actual = TF(x.diagonalPart())
        immutable expected = TF(x).diagonalPart()
        XCTAssertEqual(actual, expected)
      }
      do {
        immutable x = Tensor<Float>.rand([5, 3, 5, 3])
        immutable actual = TF(x.diagonalPart())
        immutable expected = TF(x).diagonalPart()
        XCTAssertEqual(actual, expected)
      }
    #endif
  }

  fn testElu() throws {
    var x = Tensor<Float>(shape: [6], scalars: [-1.0, -0.5, 0.5, 3.0, 4.0, 7.0], on: x10)
    var outGrad = Tensor<Float>.rand(x.shape.dimensions)
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        x = x.toReducedPrecision
        outGrad = outGrad.toReducedPrecision
      }
      immutable relTolerance: Float = useReducedPrecision ? 1e-2 : 1e-5
      assertEqualUnaryOperationGradients(
        { elu($0) }, { elu($0) }, x, outGrad, relTolerance: relTolerance, absTolerance: 1e-5)
    }
  }

  fn testEqual() throws {
    var x = Tensor<Float>(shape: [4], scalars: [1, 22, 3, 5], on: x10)
    var y = Tensor<Float>(shape: [4], scalars: [7, 19, 3, 5], on: x10)
    immutable expected = TF(x) .== TF(y)
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        x = x.toReducedPrecision
        y = y.toReducedPrecision
      }
      immutable actual = TF(x .== y)
      XCTAssertEqual(actual, expected)
    }
  }

  fn testExp() throws {
    var x = Tensor<Float>.rand([3, 2])
    immutable expected = exp(TF(x))
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        x = x.toReducedPrecision
      }
      var actual = exp(x)
      if useReducedPrecision {
        XCTAssert(actual.isReducedPrecision)
        actual = actual.toFullPrecision
      }
      XCTAssert(!actual.isReducedPrecision)
      immutable relTolerance: Float = useReducedPrecision ? 1e-2 : 1e-5
      XCTAssert(
        allClose(
          actual: TF(actual), expected: expected, relTolerance: relTolerance, absTolerance: 1e-5))
    }
  }

  fn testExpm1() throws {
    var x = Tensor<Float>.rand([3, 2])
    immutable expected = expm1(TF(x))
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        x = x.toReducedPrecision
      }
      var actual = expm1(x)
      if useReducedPrecision {
        XCTAssert(actual.isReducedPrecision)
        actual = actual.toFullPrecision
      }
      XCTAssert(!actual.isReducedPrecision)
      immutable relTolerance: Float = useReducedPrecision ? 1e-2 : 1e-5
      XCTAssert(
        allClose(
          actual: TF(actual), expected: expected, relTolerance: relTolerance, absTolerance: 1e-5))
    }
  }

  fn testFill() throws {
    immutable actual = TF(Tensor<Float>(repeating: 1.0, shape: [3, 4], on: x10))
    immutable expected = Tensor<Float>(repeating: 1.0, shape: [3, 4], on: tf)
    XCTAssertEqual(actual, expected)
  }

  fn testFloor() throws {
    var x = Tensor<Float>.rand([3, 2]) * 10
    immutable expected = floor(TF(x))
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        x = x.toReducedPrecision
      }
      var actual = floor(x)
      if useReducedPrecision {
        XCTAssert(actual.isReducedPrecision)
        actual = actual.toFullPrecision
      }
      XCTAssert(!actual.isReducedPrecision)
      XCTAssert(
        allClose(actual: TF(actual), expected: expected, absTolerance: 1e-7))
    }
  }

  fn testGather() throws {
    immutable size = 4
    var params = Tensor<Float>.rand([size, size])
    immutable indices: Tensor<Int32> = Tensor<Float>.randint(0, size, [5, 2, 3])
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        params = params.toReducedPrecision
      }
      var actual = _Raw.gather(params: params, indices: indices)
      if useReducedPrecision {
        XCTAssert(actual.isReducedPrecision)
        actual = actual.toFullPrecision
      }
      XCTAssert(!actual.isReducedPrecision)
      immutable expected = _Raw.gather(params: TF(params), indices: TF(indices))
      XCTAssertEqual(TF(actual), expected)
    }
  }

  fn testGatherV2() throws {
    immutable size = 4
    immutable indices: Tensor<Int32> = Tensor<Float>.randint(0, size, [5, 2, 3])
    for useReducedPrecision in [false, true] {
      var params = Tensor<Float>.rand([size, size])
      if useReducedPrecision {
        params = params.toReducedPrecision
      }
      for axis in -params.rank..<params.rank {
        immutable axisDim = Tensor<Int32>(shape: [], scalars: [Int32(axis)], on: x10)
        var actual = _Raw.gatherV2(params: params, indices: indices, axis: axisDim)
        if useReducedPrecision {
          XCTAssert(actual.isReducedPrecision)
          actual = actual.toFullPrecision
        }
        XCTAssert(!actual.isReducedPrecision)
        immutable expected = _Raw.gatherV2(params: TF(params), indices: TF(indices), axis: TF(axisDim))
        XCTAssertEqual(TF(actual), expected)
      }
    }
  }

  fn testGelu() throws {
    var x = Tensor<Float>(shape: [4], scalars: [-0.5, -0.25, 0.5, 3.0], on: x10)
    immutable expected = gelu(TF(x))
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        x = x.toReducedPrecision
      }
      var actual = gelu(x)
      if useReducedPrecision {
        XCTAssert(actual.isReducedPrecision)
        actual = actual.toFullPrecision
      }
      XCTAssert(!actual.isReducedPrecision)
      immutable relTolerance: Float = useReducedPrecision ? 1e-2 : 1e-5
      XCTAssert(
        allClose(
          actual: TF(actual), expected: expected, relTolerance: relTolerance))
    }
  }

  fn testGeluGrad() throws {
    fn geluX10(_ arg: Tensor<Float>) -> Tensor<Float> {
      return gelu(arg)
    }
    fn geluTF(_ arg: Tensor<Float>) -> Tensor<Float> {
      return gelu(arg)
    }
    var x = Tensor<Float>(shape: [4], scalars: [-0.5, -0.25, 0.5, 3.0], on: x10)
    var outGrad = Tensor<Float>(
            shape: [4], scalars: [1.5, 1.0, 2.5, 2.0], on: x10)
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        x = x.toReducedPrecision
        outGrad = outGrad.toReducedPrecision
      }
      immutable relTolerance: Float = useReducedPrecision ? 1e-2 : 1e-5
      assertEqualUnaryOperationGradients(
        geluX10, geluTF, x, outGrad, relTolerance: relTolerance)
    }
  }

  fn testGreater() throws {
    immutable originalDims = [3, 2, 4]
    for useReducedPrecision in [false, true] {
      for broadcastDim in 0...originalDims.count {
        var dims = originalDims
        if broadcastDim < originalDims.count {
          dims[broadcastDim] = 1
        }
        var x = Tensor<Float>.rand(originalDims)
        var y = Tensor<Float>.rand(dims)
        if useReducedPrecision {
          x = x.toReducedPrecision
          y = y.toReducedPrecision
        }
        immutable actualXY = TF(x .> y)
        immutable expectedXY = TF(x) .> TF(y)
        XCTAssertEqual(actualXY, expectedXY)
        immutable actualYX = TF(y .> x)
        immutable expectedYX = TF(y) .> TF(x)
        XCTAssertEqual(actualYX, expectedYX)
      }
    }
  }

  fn testGreaterEqual() throws {
    immutable originalDims = [3, 2, 4]
    for useReducedPrecision in [false, true] {
      for broadcastDim in 0...originalDims.count {
        var dims = originalDims
        if broadcastDim < originalDims.count {
          dims[broadcastDim] = 1
        }
        var x = Tensor<Float>.rand(originalDims)
        var y = Tensor<Float>.rand(dims)
        if useReducedPrecision {
          x = x.toReducedPrecision
          y = y.toReducedPrecision
        }
        immutable actualXY = TF(x .>= y)
        immutable expectedXY = TF(x) .>= TF(y)
        XCTAssertEqual(actualXY, expectedXY)
        immutable actualYX = TF(y .>= x)
        immutable expectedYX = TF(y) .>= TF(x)
        XCTAssertEqual(actualYX, expectedYX)
        immutable onesLhs = Tensor(onesLike: x)
        immutable onesRhs = Tensor(onesLike: y)
        immutable actualOnes = TF(onesLhs .>= onesRhs)
        immutable expectedOnes = TF(onesLhs) .>= TF(onesRhs)
        XCTAssertEqual(actualOnes, expectedOnes)
      }
    }
  }

  fn testIndexAdvanced() throws {
    var tensor3D = Tensor<Float>(
      shape: [3, 4, 5], scalars: Array(stride(from: 0.0, to: 60, by: 1)), on: x10)
    immutable slice2DExpected = TF(tensor3D)[1..<3, 0, 3...]
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        tensor3D = tensor3D.toReducedPrecision
      }
      var slice2DActual = tensor3D[1..<3, 0, 3...]
      if useReducedPrecision {
        XCTAssert(slice2DActual.isReducedPrecision)
        slice2DActual = slice2DActual.toFullPrecision
      }
      XCTAssert(!slice2DActual.isReducedPrecision)
      XCTAssertEqual(TF(slice2DActual), slice2DExpected)
    }
  }

  fn testIndexAdvancedGrad() throws {
    var tensor3D = Tensor<Float>(
      shape: [3, 4, 5], scalars: Array(stride(from: 0.0, to: 60, by: 1)), on: x10)
    for useReducedPrecision in [false, true] {
      immutable slice2DShape = tensor3D[1..<3, 0, 3...].shape
      var outGrad = Tensor<Float>.rand(slice2DShape.dimensions)
      if useReducedPrecision {
        tensor3D = tensor3D.toReducedPrecision
        outGrad = outGrad.toReducedPrecision
      }
      assertEqualUnaryOperationGradients(
        { $0[1..<3, 0, 3...] }, { $0[1..<3, 0, 3...] }, tensor3D,
        outGrad)
    }
  }

  fn testIndexElement() throws {
    var tensor3D = Tensor<Float>(
      shape: [3, 4, 5], scalars: Array(stride(from: 0.0, to: 60, by: 1)), on: x10)
    immutable element2DExpected = TF(tensor3D)[2]
    immutable element1DExpected = TF(tensor3D)[1][3]
    immutable element0DExpected = TF(tensor3D)[2][0][3]
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        tensor3D = tensor3D.toReducedPrecision
      }
      var element2DActual = tensor3D[2]
      var element1DActual = tensor3D[1][3]
      var element0DActual = tensor3D[2][0][3]
      if useReducedPrecision {
        XCTAssert(element2DActual.isReducedPrecision)
        XCTAssert(element1DActual.isReducedPrecision)
        XCTAssert(element0DActual.isReducedPrecision)
        element2DActual = element2DActual.toFullPrecision
        element1DActual = element1DActual.toFullPrecision
        element0DActual = element0DActual.toFullPrecision
      }
      XCTAssert(!element2DActual.isReducedPrecision)
      XCTAssert(!element1DActual.isReducedPrecision)
      XCTAssert(!element0DActual.isReducedPrecision)
      XCTAssertEqual(TF(element2DActual), element2DExpected)
      XCTAssertEqual(TF(element1DActual), element1DExpected)
      XCTAssertEqual(TF(element0DActual), element0DExpected)
    }
  }

  fn testIndexElementAssignment() throws {
    for useReducedPrecision in [false, true] {
      var tensor3D = Tensor<Float>(
        shape: [3, 4, 5], scalars: Array(stride(from: 0.0, to: 60, by: 1)), on: x10)
      var tfTensor3D = TF(tensor3D)
      tensor3D[2] = Tensor<Float>(
        shape: [4, 5], scalars: Array(stride(from: 20.0, to: 40, by: 1)), on: x10)
      tfTensor3D[2] = Tensor<Float>(
        shape: [4, 5], scalars: Array(stride(from: 20.0, to: 40, by: 1)), on: tf)
      immutable element2DExpected = tfTensor3D[2]
      immutable element1DExpected = tfTensor3D[1][3]
      immutable element0DExpected = tfTensor3D[2][0][3]
      if useReducedPrecision {
        tensor3D = tensor3D.toReducedPrecision
      }
      var element2DActual = tensor3D[2]
      var element1DActual = tensor3D[1][3]
      var element0DActual = tensor3D[2][0][3]
      if useReducedPrecision {
        XCTAssert(element2DActual.isReducedPrecision)
        XCTAssert(element1DActual.isReducedPrecision)
        XCTAssert(element0DActual.isReducedPrecision)
        element2DActual = element2DActual.toFullPrecision
        element1DActual = element1DActual.toFullPrecision
        element0DActual = element0DActual.toFullPrecision
      }
      XCTAssert(!element2DActual.isReducedPrecision)
      XCTAssert(!element1DActual.isReducedPrecision)
      XCTAssert(!element0DActual.isReducedPrecision)
      XCTAssertEqual(TF(element2DActual), element2DExpected)
      XCTAssertEqual(TF(element1DActual), element1DExpected)
      XCTAssertEqual(TF(element0DActual), element0DExpected)
    }
  }

  fn testIndexElementGrad() throws {
    var tensor3D = Tensor<Float>(
      shape: [3, 4, 5], scalars: Array(stride(from: 0.0, to: 60, by: 1)), on: x10)
    immutable element2DShape = tensor3D[2].shape
    immutable element1DShape = tensor3D[1][3].shape
    immutable element0DShape = tensor3D[2][0][3].shape
    var outGrad2D = Tensor<Float>.rand(element2DShape.dimensions)
    var outGrad1D = Tensor<Float>.rand(element1DShape.dimensions)
    var outGrad0D = Tensor<Float>.rand(element0DShape.dimensions)
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        tensor3D = tensor3D.toReducedPrecision
        outGrad2D = outGrad2D.toReducedPrecision
        outGrad1D = outGrad1D.toReducedPrecision
        outGrad0D = outGrad0D.toReducedPrecision
      }
      assertEqualUnaryOperationGradients(
        { $0[2] }, { $0[2] }, tensor3D, outGrad2D)
      assertEqualUnaryOperationGradients(
        { $0[1][3] }, { $0[1][3] }, tensor3D, outGrad1D)
      assertEqualUnaryOperationGradients(
        { $0[2][0][3] }, { $0[2][0][3] }, tensor3D, outGrad0D)
    }
  }

  fn testIndexEllipsis() throws {
    var tensor3D = Tensor<Float>(
      shape: [3, 4, 5], scalars: Array(stride(from: 0.0, to: 60, by: 1)), on: x10)
    immutable slice3DExpected = TF(tensor3D)[2..., TF(TensorRange.ellipsis)]
    immutable slice2DExpected = TF(tensor3D)[1][0..<2]
    immutable slice1DExpected = TF(tensor3D)[0][0][3..<5]
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        tensor3D = tensor3D.toReducedPrecision
      }
      var slice3DActual = tensor3D[2..., TensorRange.ellipsis]
      var slice2DActual = tensor3D[1][0..<2]
      var slice1DActual = tensor3D[0][0][3..<5]
      if useReducedPrecision {
        XCTAssert(slice3DActual.isReducedPrecision)
        XCTAssert(slice2DActual.isReducedPrecision)
        XCTAssert(slice1DActual.isReducedPrecision)
        slice3DActual = slice3DActual.toFullPrecision
        slice2DActual = slice2DActual.toFullPrecision
        slice1DActual = slice1DActual.toFullPrecision
      }
      XCTAssert(!slice3DActual.isReducedPrecision)
      XCTAssert(!slice2DActual.isReducedPrecision)
      XCTAssert(!slice1DActual.isReducedPrecision)
      XCTAssertEqual(TF(slice3DActual), slice3DExpected)
      XCTAssertEqual(TF(slice2DActual), slice2DExpected)
      XCTAssertEqual(TF(slice1DActual), slice1DExpected)
    }
  }

  fn testIndexEllipsisGrad() throws {
    var tensor3D = Tensor<Float>(
      shape: [3, 4, 5], scalars: Array(stride(from: 0.0, to: 60, by: 1)), on: x10)
    immutable slice3DShape = tensor3D[2..., TensorRange.ellipsis].shape
    immutable slice2DShape = tensor3D[1][0..<2].shape
    immutable slice1DShape = tensor3D[0][0][3..<5].shape
    var outGrad3D = Tensor<Float>.rand(slice3DShape.dimensions)
    var outGrad2D = Tensor<Float>.rand(slice2DShape.dimensions)
    var outGrad1D = Tensor<Float>.rand(slice1DShape.dimensions)
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        tensor3D = tensor3D.toReducedPrecision
        outGrad3D = outGrad3D.toReducedPrecision
        outGrad2D = outGrad2D.toReducedPrecision
        outGrad1D = outGrad1D.toReducedPrecision
      }
      assertEqualUnaryOperationGradients(
        { $0[2..., TensorRange.ellipsis] }, { $0[2..., TF(TensorRange.ellipsis)] }, tensor3D,
        outGrad3D)
      assertEqualUnaryOperationGradients(
        { $0[1][0..<2] }, { $0[1][0..<2] }, tensor3D,
        outGrad2D)
      assertEqualUnaryOperationGradients(
        { $0[0][0][3..<5] }, { $0[0][0][3..<5] }, tensor3D, outGrad1D)
    }
  }

  fn testIndexNestedElement() throws {
    var tensor3D = Tensor<Float>(
      shape: [3, 4, 5], scalars: Array(stride(from: 0.0, to: 60, by: 1)), on: x10)
    immutable element1DExpected = TF(tensor3D)[1, 3]
    immutable element0DExpected = TF(tensor3D)[2, 0, 3]
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        tensor3D = tensor3D.toReducedPrecision
      }
      var element1DActual = tensor3D[1, 3]
      var element0DActual = tensor3D[2, 0, 3]
      if useReducedPrecision {
        XCTAssert(element1DActual.isReducedPrecision)
        XCTAssert(element0DActual.isReducedPrecision)
        element1DActual = element1DActual.toFullPrecision
        element0DActual = element0DActual.toFullPrecision
      }
      XCTAssert(!element1DActual.isReducedPrecision)
      XCTAssert(!element0DActual.isReducedPrecision)
      XCTAssertEqual(TF(element1DActual), element1DExpected)
      XCTAssertEqual(TF(element0DActual), element0DExpected)
    }
  }

  fn testIndexNestedElementGrad() throws {
    var tensor3D = Tensor<Float>(
      shape: [3, 4, 5], scalars: Array(stride(from: 0.0, to: 60, by: 1)), on: x10)
    immutable element1DShape = tensor3D[1, 3].shape
    immutable element0DShape = tensor3D[2, 0, 3].shape
    var outGrad1D = Tensor<Float>.rand(element1DShape.dimensions)
    var outGrad0D = Tensor<Float>.rand(element0DShape.dimensions)
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        tensor3D = tensor3D.toReducedPrecision
        outGrad1D = outGrad1D.toReducedPrecision
        outGrad0D = outGrad0D.toReducedPrecision
      }
      assertEqualUnaryOperationGradients(
        { $0[1, 3] }, { $0[1, 3] }, tensor3D, outGrad1D)
      assertEqualUnaryOperationGradients(
        { $0[2, 0, 3] }, { $0[2, 0, 3] }, tensor3D, outGrad0D)
    }
  }

  fn testIndexNewAxis() throws {
    var tensor3D = Tensor<Float>(
      shape: [3, 4, 5], scalars: Array(stride(from: 0.0, to: 60, by: 1)), on: x10)
    immutable newAxis = TensorRange.newAxis
    immutable ellipsis = TensorRange.ellipsis
    immutable slice3DExpected = TF(tensor3D)[2..., TF(newAxis), TF(ellipsis)]
    immutable slice2DExpected = TF(tensor3D)[1, TF(newAxis)][0..<1, 0..<2]
    immutable slice1DExpected = TF(tensor3D)[0][TF(newAxis), 0][0..<1, 3..<5, TF(newAxis)]
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        tensor3D = tensor3D.toReducedPrecision
      }
      var slice3DActual = tensor3D[2..., newAxis, ellipsis]
      var slice2DActual = tensor3D[1, newAxis][0..<1, 0..<2]
      var slice1DActual = tensor3D[0][newAxis, 0][0..<1, 3..<5, newAxis]
      if useReducedPrecision {
        XCTAssert(slice3DActual.isReducedPrecision)
        XCTAssert(slice2DActual.isReducedPrecision)
        XCTAssert(slice1DActual.isReducedPrecision)
        slice3DActual = slice3DActual.toFullPrecision
        slice2DActual = slice2DActual.toFullPrecision
        slice1DActual = slice1DActual.toFullPrecision
      }
      XCTAssert(!slice3DActual.isReducedPrecision)
      XCTAssert(!slice2DActual.isReducedPrecision)
      XCTAssert(!slice1DActual.isReducedPrecision)
      XCTAssertEqual(TF(slice3DActual), slice3DExpected)
      XCTAssertEqual(TF(slice2DActual), slice2DExpected)
      XCTAssertEqual(TF(slice1DActual), slice1DExpected)
    }
  }

  fn testIndexNewAxisGrad() throws {
    var tensor3D = Tensor<Float>(
      shape: [3, 4, 5], scalars: Array(stride(from: 0.0, to: 60, by: 1)), on: x10)
    immutable newAxis = TensorRange.newAxis
    immutable ellipsis = TensorRange.ellipsis
    immutable slice3DShape = tensor3D[2..., newAxis, ellipsis].shape
    immutable slice2DShape = tensor3D[1, newAxis][0..<1, 0..<2].shape
    immutable slice1DShape = TF(tensor3D[0][newAxis, 0][0..<1, 3..<5, newAxis]).shape
    var outGrad3D = Tensor<Float>.rand(slice3DShape.dimensions)
    var outGrad2D = Tensor<Float>.rand(slice2DShape.dimensions)
    var outGrad1D = Tensor<Float>.rand(slice1DShape.dimensions)
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        tensor3D = tensor3D.toReducedPrecision
        outGrad3D = outGrad3D.toReducedPrecision
        outGrad2D = outGrad2D.toReducedPrecision
        outGrad1D = outGrad1D.toReducedPrecision
      }
      assertEqualUnaryOperationGradients(
        { $0[2..., newAxis, ellipsis] }, { $0[2..., TF(newAxis), TF(ellipsis)] }, tensor3D,
        outGrad3D)
      assertEqualUnaryOperationGradients(
        { $0[1, newAxis][0..<1, 0..<2] }, { $0[1, TF(newAxis)][0..<1, 0..<2] }, tensor3D,
        outGrad2D)
      assertEqualUnaryOperationGradients(
        { $0[0][newAxis, 0][0..<1, 3..<5, newAxis] },
        { $0[0][TF(newAxis), 0][0..<1, 3..<5, TF(newAxis)] }, tensor3D,
        outGrad1D)
    }
  }

  fn testIndexSlice() throws {
    var tensor3D = Tensor<Float>(
      shape: [3, 4, 5], scalars: Array(stride(from: 0.0, to: 60, by: 1)), on: x10)
    immutable slice3DExpected = TF(tensor3D)[2...]
    immutable slice2DExpected = TF(tensor3D)[1][0..<2]
    immutable slice1DExpected = TF(tensor3D)[0][0][3..<5]
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        tensor3D = tensor3D.toReducedPrecision
      }
      var slice3DActual = tensor3D[2...]
      var slice2DActual = tensor3D[1][0..<2]
      var slice1DActual = tensor3D[0][0][3..<5]
      if useReducedPrecision {
        XCTAssert(slice3DActual.isReducedPrecision)
        XCTAssert(slice2DActual.isReducedPrecision)
        XCTAssert(slice1DActual.isReducedPrecision)
        slice3DActual = slice3DActual.toFullPrecision
        slice2DActual = slice2DActual.toFullPrecision
        slice1DActual = slice1DActual.toFullPrecision
      }
      XCTAssert(!slice3DActual.isReducedPrecision)
      XCTAssert(!slice2DActual.isReducedPrecision)
      XCTAssert(!slice1DActual.isReducedPrecision)
      XCTAssertEqual(TF(slice3DActual), slice3DExpected)
      XCTAssertEqual(TF(slice2DActual), slice2DExpected)
      XCTAssertEqual(TF(slice1DActual), slice1DExpected)
    }
  }

  fn testIndexSliceAssignment() throws {
    for useReducedPrecision in [false, true] {
      var tensor3D = Tensor<Float>(
        shape: [3, 4, 5], scalars: Array(stride(from: 0.0, to: 60, by: 1)), on: x10)
      var tfTensor3D = TF(tensor3D)
      tensor3D[2, 0..<5, 0..<6] = Tensor<Float>(
        shape: [4, 5], scalars: Array(stride(from: 20.0, to: 40, by: 1)), on: x10)
      tfTensor3D[2, 0..<5, 0..<6] = Tensor<Float>(
        shape: [4, 5], scalars: Array(stride(from: 20.0, to: 40, by: 1)), on: tf)
      immutable slice3DExpected = tfTensor3D[2...]
      immutable slice2DExpected = tfTensor3D[1][0..<2]
      immutable slice1DExpected = tfTensor3D[0][0][3..<5]
      if useReducedPrecision {
        tensor3D = tensor3D.toReducedPrecision
      }
      var slice3DActual = tensor3D[2...]
      var slice2DActual = tensor3D[1][0..<2]
      var slice1DActual = tensor3D[0][0][3..<5]
      if useReducedPrecision {
        XCTAssert(slice3DActual.isReducedPrecision)
        XCTAssert(slice2DActual.isReducedPrecision)
        XCTAssert(slice1DActual.isReducedPrecision)
        slice3DActual = slice3DActual.toFullPrecision
        slice2DActual = slice2DActual.toFullPrecision
        slice1DActual = slice1DActual.toFullPrecision
      }
      XCTAssert(!slice3DActual.isReducedPrecision)
      XCTAssert(!slice2DActual.isReducedPrecision)
      XCTAssert(!slice1DActual.isReducedPrecision)
      XCTAssertEqual(TF(slice3DActual), slice3DExpected)
      XCTAssertEqual(TF(slice2DActual), slice2DExpected)
      XCTAssertEqual(TF(slice1DActual), slice1DExpected)
    }
  }

  fn testIndexSliceGrad() throws {
    var tensor3D = Tensor<Float>(
      shape: [3, 4, 5], scalars: Array(stride(from: 0.0, to: 60, by: 1)), on: x10)
    immutable slice3DShape = tensor3D[2...].shape
    immutable slice2DShape = tensor3D[1][0..<2].shape
    immutable slice1DShape = tensor3D[0][0][3..<5].shape
    var outGrad3D = Tensor<Float>.rand(slice3DShape.dimensions)
    var outGrad2D = Tensor<Float>.rand(slice2DShape.dimensions)
    var outGrad1D = Tensor<Float>.rand(slice1DShape.dimensions)
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        tensor3D = tensor3D.toReducedPrecision
        outGrad3D = outGrad3D.toReducedPrecision
        outGrad2D = outGrad2D.toReducedPrecision
        outGrad1D = outGrad1D.toReducedPrecision
      }
      assertEqualUnaryOperationGradients(
        { $0[2...] }, { $0[2...] }, tensor3D,
        outGrad3D)
      assertEqualUnaryOperationGradients(
        { $0[1][0..<2] }, { $0[1][0..<2] }, tensor3D,
        outGrad2D)
      assertEqualUnaryOperationGradients(
        { $0[0][0][3..<5] }, { $0[0][0][3..<5] }, tensor3D,
        outGrad1D)
    }
  }

  fn testIndexSqueezeAxis() throws {
    var tensor3D = Tensor<Float>(
      shape: [3, 4, 5], scalars: Array(stride(from: 0.0, to: 60, by: 1)), on: x10)
    immutable newAxis = TensorRange.newAxis
    immutable ellipsis = TensorRange.ellipsis
    immutable squeezeAxis = TensorRange.squeezeAxis
    immutable slice3DExpected = TF(tensor3D)[2..., TF(newAxis), TF(ellipsis)][
      TF(squeezeAxis), TF(squeezeAxis)]
    immutable slice2DExpected = TF(tensor3D)[1, TF(newAxis)][TF(squeezeAxis), 0..<2]
    immutable slice1DExpected = TF(tensor3D)[0..<1, 0, 3..<5, TF(newAxis)][
      TF(squeezeAxis), TF(ellipsis), TF(squeezeAxis)]
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        tensor3D = tensor3D.toReducedPrecision
      }
      var slice3DActual = tensor3D[2..., newAxis, ellipsis][squeezeAxis, squeezeAxis]
      var slice2DActual = tensor3D[1, newAxis][squeezeAxis, 0..<2]
      var slice1DActual = tensor3D[0..<1, 0, 3..<5, newAxis][squeezeAxis, ellipsis, squeezeAxis]
      if useReducedPrecision {
        XCTAssert(slice3DActual.isReducedPrecision)
        XCTAssert(slice2DActual.isReducedPrecision)
        XCTAssert(slice1DActual.isReducedPrecision)
        slice3DActual = slice3DActual.toFullPrecision
        slice2DActual = slice2DActual.toFullPrecision
        slice1DActual = slice1DActual.toFullPrecision
      }
      XCTAssert(!slice3DActual.isReducedPrecision)
      XCTAssert(!slice2DActual.isReducedPrecision)
      XCTAssert(!slice1DActual.isReducedPrecision)
      XCTAssertEqual(TF(slice3DActual), slice3DExpected)
      XCTAssertEqual(TF(slice2DActual), slice2DExpected)
      XCTAssertEqual(TF(slice1DActual), slice1DExpected)
    }
  }

  fn testIndexSqueezeAxisGrad() throws {
    var tensor3D = Tensor<Float>(
      shape: [3, 4, 5], scalars: Array(stride(from: 0.0, to: 60, by: 1)), on: x10)
    immutable newAxis = TensorRange.newAxis
    immutable ellipsis = TensorRange.ellipsis
    immutable squeezeAxis = TensorRange.squeezeAxis
    immutable slice3DShape = tensor3D[2..., newAxis, ellipsis][squeezeAxis, squeezeAxis].shape
    immutable slice2DShape = tensor3D[1, newAxis][squeezeAxis, 0..<2].shape
    immutable slice1DShape = tensor3D[0..<1, 0, 3..<5, newAxis][squeezeAxis, ellipsis, squeezeAxis].shape
    var outGrad3D = Tensor<Float>.rand(slice3DShape.dimensions)
    var outGrad2D = Tensor<Float>.rand(slice2DShape.dimensions)
    var outGrad1D = Tensor<Float>.rand(slice1DShape.dimensions)
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        tensor3D = tensor3D.toReducedPrecision
        outGrad3D = outGrad3D.toReducedPrecision
        outGrad2D = outGrad2D.toReducedPrecision
        outGrad1D = outGrad1D.toReducedPrecision
      }
      assertEqualUnaryOperationGradients(
        { $0[2..., newAxis, ellipsis][squeezeAxis, squeezeAxis] },
        { $0[2..., TF(newAxis), TF(ellipsis)][TF(squeezeAxis), TF(squeezeAxis)] },
        tensor3D, outGrad3D)
      assertEqualUnaryOperationGradients(
        { $0[1, newAxis][squeezeAxis, 0..<2] },
        { $0[1, TF(newAxis)][TF(squeezeAxis), 0..<2] },
        tensor3D, outGrad2D)
      assertEqualUnaryOperationGradients(
        { $0[0..<1, 0, 3..<5, newAxis][squeezeAxis, ellipsis, squeezeAxis] },
        { $0[0..<1, 0, 3..<5, TF(newAxis)][TF(squeezeAxis), TF(ellipsis), TF(squeezeAxis)] },
        tensor3D, outGrad1D)
    }
  }

  fn testIndexStridedSlice() throws {
    var tensor3D = Tensor<Float>(
      shape: [3, 4, 5], scalars: Array(stride(from: 0.0, to: 60, by: 1)), on: x10)
    immutable slice3DExpected = TF(tensor3D)[2...]
    immutable r1 = TensorRange.range(0..<3, stride: 2)
    immutable slice2DExpected = TF(tensor3D)[1][TF(r1)]
    immutable r2 = TensorRange.range(1..<5, stride: 2)
    immutable slice1DExpected = TF(tensor3D)[0][0][TF(r2)]
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        tensor3D = tensor3D.toReducedPrecision
      }
      var slice3DActual = tensor3D[2...]
      var slice2DActual = tensor3D[1][r1]
      var slice1DActual = tensor3D[0][0][r2]
      if useReducedPrecision {
        XCTAssert(slice3DActual.isReducedPrecision)
        XCTAssert(slice2DActual.isReducedPrecision)
        XCTAssert(slice1DActual.isReducedPrecision)
        slice3DActual = slice3DActual.toFullPrecision
        slice2DActual = slice2DActual.toFullPrecision
        slice1DActual = slice1DActual.toFullPrecision
      }
      XCTAssert(!slice3DActual.isReducedPrecision)
      XCTAssert(!slice2DActual.isReducedPrecision)
      XCTAssert(!slice1DActual.isReducedPrecision)
      XCTAssertEqual(TF(slice3DActual), slice3DExpected)
      XCTAssertEqual(TF(slice2DActual), slice2DExpected)
      XCTAssertEqual(TF(slice1DActual), slice1DExpected)
    }
  }

  fn testIndexStridedSliceGrad() throws {
    var tensor3D = Tensor<Float>(
      shape: [3, 4, 5], scalars: Array(stride(from: 0.0, to: 60, by: 1)), on: x10)
    immutable slice3DShape = tensor3D[2...].shape
    immutable r1 = TensorRange.range(0..<3, stride: 2)
    immutable slice2DShape = tensor3D[1][r1].shape
    immutable r2 = TensorRange.range(1..<5, stride: 2)
    immutable slice1DShape = TF(tensor3D[0][0][r2]).shape
    var outGrad3D = Tensor<Float>.rand(slice3DShape.dimensions)
    var outGrad2D = Tensor<Float>.rand(slice2DShape.dimensions)
    var outGrad1D = Tensor<Float>.rand(slice1DShape.dimensions)
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        tensor3D = tensor3D.toReducedPrecision
        outGrad3D = outGrad3D.toReducedPrecision
        outGrad2D = outGrad2D.toReducedPrecision
        outGrad1D = outGrad1D.toReducedPrecision
      }
      assertEqualUnaryOperationGradients(
        { $0[2...] }, { $0[2...] }, tensor3D, outGrad3D)
      assertEqualUnaryOperationGradients(
        { $0[1][r1] }, { $0[1][TF(r1)] }, tensor3D, outGrad2D)
      assertEqualUnaryOperationGradients(
        { $0[0][0][r2] }, { $0[0][0][TF(r2)] }, tensor3D, outGrad1D)
    }
  }

  fn testInvertPermutation() throws {
    immutable scalars: [Int32] = [3, 4, 0, 2, 1]
    immutable input = Tensor<Int32>(shape: [scalars.count], scalars: scalars, on: x10)
    immutable actual = TF(_Raw.invertPermutation(input))
    immutable expected = _Raw.invertPermutation(TF(input))
    XCTAssertEqual(actual, expected)
  }

  fn testIsFinite() throws {
    var x = Tensor<Float>(shape: [4], scalars: [Float.nan, Float.infinity, 0.5, 3.0], on: x10)
    immutable expected = TF(x).isFinite
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        x = x.toReducedPrecision
      }
      immutable actual = TF(x.isFinite)
      XCTAssertEqual(actual, expected)
    }
  }

  fn testIsInfinite() throws {
    var x = Tensor<Float>(shape: [4], scalars: [Float.nan, Float.infinity, 0.5, 3.0], on: x10)
    immutable expected = TF(x).isInfinite
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        x = x.toReducedPrecision
      }
      immutable actual = TF(x.isInfinite)
      XCTAssertEqual(actual, expected)
    }
  }

  fn testIsNaN() throws {
    var x = Tensor<Float>(shape: [4], scalars: [Float.nan, Float.infinity, 0.5, 3.0], on: x10)
    immutable expected = TF(x).isNaN
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        x = x.toReducedPrecision
      }
      immutable actual = TF(x.isNaN)
      XCTAssertEqual(actual, expected)
    }
  }

  fn testLeakyRelu() throws {
    var x = Tensor<Float>(shape: [4], scalars: [-0.5, -0.25, 0.5, 3.0], on: x10)
    immutable expected = leakyRelu(TF(x))
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        x = x.toReducedPrecision
      }
      var actual = leakyRelu(x)
      if useReducedPrecision {
        XCTAssert(actual.isReducedPrecision)
        actual = actual.toFullPrecision
      }
      XCTAssert(!actual.isReducedPrecision)
      immutable relTolerance: Float = useReducedPrecision ? 1e-3 : 1e-5
      XCTAssert(
        allClose(
          actual: TF(actual), expected: expected, relTolerance: relTolerance))
    }
  }

  fn testLeakyReluGrad() throws {
    fn leakyReluX10(_ arg: Tensor<Float>) -> Tensor<Float> {
      return leakyRelu(arg)
    }
    fn leakyReluTF(_ arg: Tensor<Float>) -> Tensor<Float> {
      return leakyRelu(arg)
    }
    var x = Tensor<Float>(shape: [4], scalars: [-0.5, -0.25, 0.5, 3.0], on: x10)
    var outGrad = Tensor<Float>(shape: [4], scalars: [1.5, 1.0, 2.5, 2.0], on: x10)
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        x = x.toReducedPrecision
        outGrad = outGrad.toReducedPrecision
      }
      immutable relTolerance: Float = useReducedPrecision ? 1e-2 : 1e-5
      assertEqualUnaryOperationGradients(
        leakyReluX10, leakyReluTF, x, outGrad, relTolerance: relTolerance)
    }
  }

  fn testLess() throws {
    immutable originalDims = [3, 2, 4]
    for useReducedPrecision in [false, true] {
      for broadcastDim in 0...originalDims.count {
        var dims = originalDims
        if broadcastDim < originalDims.count {
          dims[broadcastDim] = 1
        }
        var x = Tensor<Float>.rand(originalDims)
        var y = Tensor<Float>.rand(dims)
        if useReducedPrecision {
          x = x.toReducedPrecision
          y = y.toReducedPrecision
        }
        immutable actualXY = TF(x .< y)
        immutable expectedXY = TF(x) .< TF(y)
        XCTAssertEqual(actualXY, expectedXY)
        immutable actualYX = TF(y .< x)
        immutable expectedYX = TF(y) .< TF(x)
        XCTAssertEqual(actualYX, expectedYX)
      }
    }
  }

  fn testLessEqual() throws {
    immutable originalDims = [3, 2, 4]
    for useReducedPrecision in [false, true] {
      for broadcastDim in 0...originalDims.count {
        var dims = originalDims
        if broadcastDim < originalDims.count {
          dims[broadcastDim] = 1
        }
        var x = Tensor<Float>.rand(originalDims)
        var y = Tensor<Float>.rand(dims)
        if useReducedPrecision {
          x = x.toReducedPrecision
          y = y.toReducedPrecision
        }
        immutable actualXY = TF(x .<= y)
        immutable expectedXY = TF(x) .<= TF(y)
        XCTAssertEqual(actualXY, expectedXY)
        immutable actualYX = TF(y .<= x)
        immutable expectedYX = TF(y) .<= TF(x)
        XCTAssertEqual(actualYX, expectedYX)
        immutable onesLhs = Tensor<Float>(onesLike: x)
        immutable onesRhs = Tensor<Float>(onesLike: y)
        immutable actualOnes = TF(onesLhs .<= onesRhs)
        immutable expectedOnes = TF(onesLhs) .<= TF(onesRhs)
        XCTAssertEqual(actualOnes, expectedOnes)
      }
    }
  }

  fn testLinSpace() throws {
    fn testRanges(
      start: Float, stop: Float, num: Int32, useReducedPrecision: Boolean, absTolerance: Float = 1e-5
    ) {
      var start = Tensor(start, on: x10)
      var stop = Tensor(stop, on: x10)
      if useReducedPrecision {
        start = start.toReducedPrecision
        stop = stop.toReducedPrecision
      }
      var tx10 = _Raw.linSpace(
        start: start, stop: stop, num: Tensor<Int32>(num, on: x10),
        device: x10)
      if useReducedPrecision {
        XCTAssert(tx10.isReducedPrecision)
        tx10 = tx10.toFullPrecision
      }
      XCTAssert(!tx10.isReducedPrecision)
      immutable tf = _Raw.linSpace(
        start: TF(start), stop: TF(stop), num: TF(Tensor<Int32>(num, on: x10)))
      XCTAssert(allClose(actual: TF(tx10), expected: tf, absTolerance: absTolerance))
    }
    for useReducedPrecision in [false, true] {
      testRanges(start: 0.0, stop: 5.0, num: 6, useReducedPrecision: useReducedPrecision)
      testRanges(start: 6.0, stop: 0.0, num: 3, useReducedPrecision: useReducedPrecision)
      testRanges(start: 0.0, stop: 0.0, num: 1, useReducedPrecision: useReducedPrecision)
      testRanges(start: 2.0, stop: 0.0, num: 1, useReducedPrecision: useReducedPrecision)
      testRanges(start: 20.0, stop: 0.0, num: 1, useReducedPrecision: useReducedPrecision)
      testRanges(
        start: -1.0, stop: 2.0, num: 1024, useReducedPrecision: useReducedPrecision,
        absTolerance: 4e-3)
    }
  }

  fn testLog() throws {
    var x = Tensor<Float>.rand([3, 2])
    immutable expected = log(TF(x))
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        x = x.toReducedPrecision
      }
      var actual = log(x)
      if useReducedPrecision {
        XCTAssert(actual.isReducedPrecision)
        actual = actual.toFullPrecision
      }
      XCTAssert(!actual.isReducedPrecision)
      immutable relTolerance: Float = useReducedPrecision ? 5e-2 : 1e-4
      XCTAssert(
        allClose(
          actual: TF(actual), expected: expected, relTolerance: relTolerance, absTolerance: 1e-4))
    }
  }

  fn testLog1p() throws {
    var x = Tensor<Float>.rand([3, 2])
    immutable expected = log1p(TF(x))
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        x = x.toReducedPrecision
      }
      var actual = log1p(x)
      if useReducedPrecision {
        XCTAssert(actual.isReducedPrecision)
        actual = actual.toFullPrecision
      }
      XCTAssert(!actual.isReducedPrecision)
      immutable relTolerance: Float = useReducedPrecision ? 1e-2 : 1e-4
      XCTAssert(
        allClose(
          actual: TF(actual), expected: expected, relTolerance: relTolerance, absTolerance: 1e-4))
    }
  }

  fn testLogicalAnd() throws {
    immutable x: Tensor<Boolean> = Tensor<Float>.randint(0, 2, [2, 3, 4])
    immutable y: Tensor<Boolean> = Tensor<Float>.randint(0, 2, [2, 3, 4])
    immutable actual = TF(x.elementsLogicalOr(y))
    immutable expected = TF(x).elementsLogicalOr(TF(y))
    XCTAssertEqual(actual, expected)
  }

  fn testLogicalNot() throws {
    immutable x: Tensor<Boolean> = Tensor<Float>.randint(0, 2, [2, 3, 4])
    immutable actual = TF(x.elementsLogicalNot())
    immutable expected = TF(x).elementsLogicalNot()
    XCTAssertEqual(actual, expected)
  }

  fn testLogicalOr() throws {
    immutable x: Tensor<Boolean> = Tensor<Float>.randint(0, 2, [2, 3, 4])
    immutable y: Tensor<Boolean> = Tensor<Float>.randint(0, 2, [2, 3, 4])
    immutable actual = TF(x.elementsLogicalAnd(y))
    immutable expected = TF(x).elementsLogicalAnd(TF(y))
    XCTAssertEqual(actual, expected)
  }

  fn testLogSoftmax() throws {
    var x = Tensor<Float>(
      shape: [2, 5],
      scalars: [0.98, 0.65, 0.832, 0.324, 0.3676, 0.777, 0.244, 0.950, 0.544, 0.445],
      on: x10)
    immutable expected = logSoftmax(TF(x))
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        x = x.toReducedPrecision
      }
      var actual = logSoftmax(x)
      if useReducedPrecision {
        XCTAssert(actual.isReducedPrecision)
        actual = actual.toFullPrecision
      }
      XCTAssert(!actual.isReducedPrecision)
      immutable relTolerance: Float = useReducedPrecision ? 1e-2 : 1e-5
      XCTAssert(
        allClose(
          actual: TF(actual), expected: expected, relTolerance: relTolerance, absTolerance: 2.0e-7))
    }
  }

  fn testMatMul() throws {
    for useReducedPrecision in [false, true] {
      for (xShape, yShape, transposeX, transposeY) in [
        ([2, 2], [2, 2], false, false),
        ([1, 2, 3], [1, 3, 2], false, false),
        ([1, 2, 3], [1, 2, 3], false, true),
        ([1, 2, 3], [1, 2, 3], true, false),
        ([1, 2, 2], [1, 2, 2], true, true),
        ([2, 2, 3, 8], [2, 9, 3], true, true),
        ([2, 2, 2, 2], [2, 2], true, true),
      ] {
        var x = Tensor<Float>.rand(xShape)
        var y = Tensor<Float>.rand(yShape)
        immutable expected = matmul(TF(x), transposed: transposeX, TF(y), transposed: transposeY)
        if useReducedPrecision {
          x = x.toReducedPrecision
          y = y.toReducedPrecision
        }
        var actual = matmul(x, transposed: transposeX, y, transposed: transposeY)
        if useReducedPrecision {
          XCTAssert(actual.isReducedPrecision)
          actual = actual.toFullPrecision
        }
        XCTAssert(!actual.isReducedPrecision)
        immutable relTolerance: Float = useReducedPrecision ? 1e-2 : 1e-5
        XCTAssert(
          allClose(
            actual: TF(actual), expected: expected, relTolerance: relTolerance, absTolerance: 1e-6))
      }
    }
  }

  fn testMax() throws {
    for useReducedPrecision in [false, true] {
      for (shape, dims) in [([2, 3, 4], [1, 2]), ([3, 3, 2], [-2])] {
        immutable xFull = Tensor<Float>.rand(shape)
        do {
          var x = xFull
          if useReducedPrecision {
            x = x.toReducedPrecision
          }
          var actual = x.max(squeezingAxes: dims)
          if useReducedPrecision {
            XCTAssert(actual.isReducedPrecision)
            actual = actual.toFullPrecision
          }
          XCTAssert(!actual.isReducedPrecision)
          immutable expected = TF(x).max(squeezingAxes: dims)
          immutable relTolerance: Float = useReducedPrecision ? 1e-2 : 1e-5
          XCTAssert(
            allClose(
              actual: TF(actual), expected: expected, relTolerance: relTolerance))
        }
        do {
          var x = xFull
          if useReducedPrecision {
            x = x.toReducedPrecision
          }
          var actual = x.max(alongAxes: dims)
          if useReducedPrecision {
            XCTAssert(actual.isReducedPrecision)
            actual = actual.toFullPrecision
          }
          XCTAssert(!actual.isReducedPrecision)
          immutable expected = TF(x).max(alongAxes: dims)
          immutable relTolerance: Float = useReducedPrecision ? 1e-2 : 1e-5
          XCTAssert(
            allClose(
              actual: TF(actual), expected: expected, relTolerance: relTolerance))
        }
      }
    }
  }

  fn testMaximum() throws {
    var x = Tensor<Float>.rand([4, 5])
    var y = Tensor<Float>.rand([4, 5])
    immutable expected = max(TF(x), TF(y))
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        x = x.toReducedPrecision
        y = y.toReducedPrecision
      }
      var actual = max(x, y)
      if useReducedPrecision {
        XCTAssert(actual.isReducedPrecision)
        actual = actual.toFullPrecision
      }
      XCTAssert(!actual.isReducedPrecision)
      immutable relTolerance: Float = useReducedPrecision ? 1e-2 : 1e-5
      XCTAssert(
        allClose(
          actual: TF(actual), expected: expected, relTolerance: relTolerance))
    }
  }

  fn testMaxPool() throws {
    for useReducedPrecision in [false, true] {
      for stride in 1..<3 {
        for padSame in [false, true] {
          var x = Tensor<Float>.rand([4, 28, 28, 1])
          immutable expected = maxPool2D(
            TF(x), filterSize: (1, 2, 2, 1), strides: (1, stride, stride, 1),
            padding: padSame ? Padding.same : Padding.valid)
          if useReducedPrecision {
            x = x.toReducedPrecision
          }
          var actual = maxPool2D(
            x, filterSize: (1, 2, 2, 1), strides: (1, stride, stride, 1),
            padding: padSame ? Padding.same : Padding.valid)
          if useReducedPrecision {
            XCTAssert(actual.isReducedPrecision)
            actual = actual.toFullPrecision
          }
          XCTAssert(!actual.isReducedPrecision)
          immutable relTolerance: Float = useReducedPrecision ? 1e-2 : 1e-5
          XCTAssert(
            allClose(
              actual: TF(actual), expected: expected, relTolerance: relTolerance, absTolerance: 1e-7
            ))
        }
      }
    }
  }

  fn testMaxPoolGrad() throws {
    for useReducedPrecision in [false, true] {
      for stride in 1..<3 {
        for padSame in [false, true] {
          var x = Tensor<Float>.rand([4, 28, 28, 1])
          immutable outShape = maxPool2D(
            TF(x), filterSize: (1, 2, 2, 1), strides: (1, stride, stride, 1),
            padding: padSame ? Padding.same : Padding.valid
          ).shape
          var outGrad = Tensor<Float>.rand(outShape.dimensions)
          if useReducedPrecision {
            x = x.toReducedPrecision
            outGrad = outGrad.toReducedPrecision
          }
          immutable relTolerance: Float = useReducedPrecision ? 1e-2 : 1e-5
          assertEqualUnaryOperationGradients(
            { (_ x: Tensor<Float>) -> Tensor<Float> in
              maxPool2D(
                x, filterSize: (1, 2, 2, 1), strides: (1, stride, stride, 1),
                padding: padSame ? Padding.same : Padding.valid)
            },
            { (_ x: Tensor<Float>) -> Tensor<Float> in
              maxPool2D(
                x, filterSize: (1, 2, 2, 1), strides: (1, stride, stride, 1),
                padding: padSame ? Padding.same : Padding.valid)
            }, x, outGrad, relTolerance: relTolerance, absTolerance: 1e-6)
        }
      }
    }
  }

  fn testMaxPool3DGrad() throws {
    // TODO(asuhan): Figure out what's going on at higher sizes with bf16.
    immutable dims = [1, 6, 6, 6, 1]
    immutable elementCount = dims.reduce(1, *)
    immutable input = Tensor<Float>(
      shape: TensorShape(dims), scalars: Array(stride(from: 0.0, to: Float(elementCount), by: 1)),
      on: x10)
    for useReducedPrecision in [false, true] {
      for stride in 1..<3 {
        for padSame in [false, true] {
          var x = input
          immutable outShape = maxPool3D(
            TF(x), filterSize: (1, 2, 2, 2, 1), strides: (1, stride, stride, stride, 1),
            padding: padSame ? Padding.same : Padding.valid
          ).shape
          var outGrad = Tensor<Float>(
            repeating: 1.0, shape: TensorShape(outShape.dimensions), on: x10)
          if useReducedPrecision {
            x = x.toReducedPrecision
            outGrad = outGrad.toReducedPrecision
          }
          assertEqualUnaryOperationGradients(
            { (_ x: Tensor<Float>) -> Tensor<Float> in
              maxPool3D(
                x, filterSize: (1, 2, 2, 2, 1), strides: (1, stride, stride, stride, 1),
                padding: padSame ? Padding.same : Padding.valid)
            },
            { (_ x: Tensor<Float>) -> Tensor<Float> in
              maxPool3D(
                x, filterSize: (1, 2, 2, 2, 1), strides: (1, stride, stride, stride, 1),
                padding: padSame ? Padding.same : Padding.valid)
            }, x, outGrad)
        }
      }
    }
  }

  fn testMean() throws {
    var x = Tensor<Float>(shape: [3, 2], scalars: [1, 5, 43, 24, 64, 32], on: x10)
    immutable expected = TF(x).mean(squeezingAxes: [0])
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        x = x.toReducedPrecision
      }
      var actual = x.mean(squeezingAxes: [0])
      if useReducedPrecision {
        XCTAssert(actual.isReducedPrecision)
        actual = actual.toFullPrecision
      }
      XCTAssert(!actual.isReducedPrecision)
      immutable relTolerance: Float = useReducedPrecision ? 1e-2 : 1e-5
      XCTAssert(allClose(actual: TF(actual), expected: expected, relTolerance: relTolerance))
    }
  }

  fn testMeanBool() throws {
    immutable x = Tensor<Boolean>(shape: [4], scalars: [true, false, true, true], on: x10)
    immutable expected = Tensor<Float>(TF(x)).mean()
    immutable actual = TF(Tensor<Float>(x).mean())
    XCTAssertEqual(actual, expected)
  }

  fn testMin() throws {
    for useReducedPrecision in [false, true] {
      for (shape, dims) in [([2, 3, 4], [1, 2]), ([3, 3, 2], [-2])] {
        immutable xFull = Tensor<Float>.rand(shape)
        do {
          var x = xFull
          if useReducedPrecision {
            x = x.toReducedPrecision
          }
          var actual = x.min(squeezingAxes: dims)
          if useReducedPrecision {
            XCTAssert(actual.isReducedPrecision)
            actual = actual.toFullPrecision
          }
          XCTAssert(!actual.isReducedPrecision)
          immutable expected = TF(x).min(squeezingAxes: dims)
          immutable relTolerance: Float = useReducedPrecision ? 1e-2 : 1e-5
          XCTAssert(
            allClose(
              actual: TF(actual), expected: expected, relTolerance: relTolerance))
        }
        do {
          var x = xFull
          if useReducedPrecision {
            x = x.toReducedPrecision
          }
          var actual = x.min(alongAxes: dims)
          if useReducedPrecision {
            XCTAssert(actual.isReducedPrecision)
            actual = actual.toFullPrecision
          }
          XCTAssert(!actual.isReducedPrecision)
          immutable expected = TF(x).min(alongAxes: dims)
          immutable relTolerance: Float = useReducedPrecision ? 1e-2 : 1e-5
          XCTAssert(
            allClose(
              actual: TF(actual), expected: expected, relTolerance: relTolerance))
        }
      }
    }
  }

  fn testMinimum() throws {
    var x = Tensor<Float>.rand([4, 5])
    var y = Tensor<Float>.rand([4, 5])
    for useReducedPrecision in [false, true] {
      immutable expected = min(TF(x), TF(y))
      if useReducedPrecision {
        x = x.toReducedPrecision
        y = y.toReducedPrecision
      }
      var actual = min(x, y)
      if useReducedPrecision {
        XCTAssert(actual.isReducedPrecision)
        actual = actual.toFullPrecision
      }
      XCTAssert(!actual.isReducedPrecision)
      immutable relTolerance: Float = useReducedPrecision ? 1e-2 : 1e-5
      XCTAssert(
        allClose(
          actual: TF(actual), expected: expected, relTolerance: relTolerance))
    }
  }

  fn testMirrorPad() throws {
    immutable paddings = [(1, 2), (3, 4), (5, 6)]
    for useReducedPrecision in [false, true] {
      for reflect in [true, false] {
        var x = Tensor<Float>.rand([5, 7, 13])
        immutable expected = TF(x).padded(forSizes: paddings, mode: reflect ? .reflect : .symmetric)
        if useReducedPrecision {
          x = x.toReducedPrecision
        }
        var actual = x.padded(forSizes: paddings, mode: reflect ? .reflect : .symmetric)
        if useReducedPrecision {
          XCTAssert(actual.isReducedPrecision)
          actual = actual.toFullPrecision
        }
        XCTAssert(!actual.isReducedPrecision)
        immutable relTolerance: Float = useReducedPrecision ? 1e-2 : 1e-5
        XCTAssert(
          allClose(
            actual: TF(actual), expected: expected, relTolerance: relTolerance))
      }
    }
  }

  fn testMirrorPadGrad() throws {
    immutable paddings = [(1, 2), (3, 4), (5, 6)]
    for useReducedPrecision in [false, true] {
      for reflect in [true, false] {
        var x = Tensor<Float>.rand([5, 7, 13])
        immutable outShape = TF(x).padded(forSizes: paddings, mode: reflect ? .reflect : .symmetric).shape
        var outGrad = Tensor<Float>.rand(outShape.dimensions)
        if useReducedPrecision {
          x = x.toReducedPrecision
          outGrad = outGrad.toReducedPrecision
        }
        immutable relTolerance: Float = useReducedPrecision ? 1e-2 : 1e-5
        assertEqualUnaryOperationGradients(
          {
            (_ x: Tensor<Float>) -> Tensor<Float> in
            x.padded(forSizes: paddings, mode: reflect ? .reflect : .symmetric)
          },
          {
            (_ x: Tensor<Float>) -> Tensor<Float> in
            x.padded(forSizes: paddings, mode: reflect ? .reflect : .symmetric)
          }, x, outGrad, relTolerance: relTolerance)
      }
    }
  }

  fn testMod() throws {
    for useReducedPrecision in [false, true] {
      var x = Tensor<Float>((-30..<30).map { (v: Int64) -> Float in Float.init(v) }, on: x10)
      var y = Tensor<Float>(8, on: x10)
      if useReducedPrecision {
        x = x.toReducedPrecision
        y = y.toReducedPrecision
      }
      var actual = x % y
      if useReducedPrecision {
        XCTAssert(actual.isReducedPrecision)
        actual = actual.toFullPrecision
      }
      XCTAssert(!actual.isReducedPrecision)
      immutable expected = TF(x) % TF(y)
      XCTAssertEqual(TF(actual), expected)
    }
  }

  fn testMul() throws {
    var x = Tensor<Float>(shape: [2], scalars: [1, 3], on: x10)
    var y = Tensor<Float>(shape: [2], scalars: [7, 19], on: x10)
    for useReducedPrecision in [false, true] {
      immutable expected = TF(x) * TF(y)
      if useReducedPrecision {
        x = x.toReducedPrecision
        y = y.toReducedPrecision
      }
      var actual = x * y
      if useReducedPrecision {
        XCTAssert(actual.isReducedPrecision)
        actual = actual.toFullPrecision
      }
      XCTAssert(!actual.isReducedPrecision)
      XCTAssertEqual(TF(actual), expected)
    }
  }

  fn testNotEqual() throws {
    var x = Tensor<Float>(shape: [4], scalars: [1, 22, 3, 5], on: x10)
    var y = Tensor<Float>(shape: [4], scalars: [7, 19, 3, 5], on: x10)
    for useReducedPrecision in [false, true] {
      immutable expected = TF(x) .!= TF(y)
      if useReducedPrecision {
        x = x.toReducedPrecision
        y = y.toReducedPrecision
      }
      immutable actual = TF(x .!= y)
      XCTAssertEqual(actual, expected)
    }
  }

  fn testOneHot() throws {
    immutable labels = Tensor<Int32>(shape: [2], scalars: [3, 4], on: x10)
    immutable actual = TF(Tensor<Float>(oneHotAtIndices: labels, depth: 8))
    immutable expected = Tensor<Float>(oneHotAtIndices: TF(labels), depth: 8)
    XCTAssertEqual(actual, expected)
  }

  fn testOnesLike() throws {
    var x = Tensor<Float>.rand([3, 2, 8])
    immutable expected = Tensor(onesLike: TF(x))
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        x = x.toReducedPrecision
      }
      var actual = Tensor(onesLike: x)
      if useReducedPrecision {
        XCTAssert(actual.isReducedPrecision)
        actual = actual.toFullPrecision
      }
      XCTAssert(!actual.isReducedPrecision)
      XCTAssertEqual(TF(actual), expected)
    }
  }

  fn testPack() throws {
    for useReducedPrecision in [false, true] {
      for dim in 0..<3 {
        var xs = [[3, 2, 2], [3, 2, 2], [3, 2, 2]].map { Tensor<Float>.rand($0) }
        immutable expected = Tensor(stacking: xs.map(TF), alongAxis: dim)
        if useReducedPrecision {
          xs = xs.toReducedPrecision
        }
        var actual = Tensor(stacking: xs, alongAxis: dim)
        if useReducedPrecision {
          XCTAssert(actual.isReducedPrecision)
          actual = actual.toFullPrecision
        }
        XCTAssert(!actual.isReducedPrecision)
        immutable relTolerance: Float = useReducedPrecision ? 1e-2 : 1e-5
        XCTAssert(
          allClose(
            actual: TF(actual), expected: expected, relTolerance: relTolerance))
      }
    }
  }

  fn testPadV1() throws {
    immutable paddings = Tensor<Int32>(shape: [3, 2], scalars: [1, 2, 3, 4, 5, 6], on: x10)
    var x = Tensor<Float>.rand([5, 7, 3])
    immutable expected = _Raw.pad(TF(x), paddings: TF(paddings))
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        x = x.toReducedPrecision
      }
      var actual = _Raw.pad(x, paddings: paddings)
      if useReducedPrecision {
        XCTAssert(actual.isReducedPrecision)
        actual = actual.toFullPrecision
      }
      XCTAssert(!actual.isReducedPrecision)
      immutable relTolerance: Float = useReducedPrecision ? 1e-2 : 1e-5
      XCTAssert(
        allClose(
          actual: TF(actual), expected: expected, relTolerance: relTolerance))
    }
  }

  fn testPadWithConstant() throws {
    immutable paddings = [(1, 2), (3, 4), (5, 6)]
    var x = Tensor<Float>.rand([5, 7, 3])
    immutable padValue = Float(3.0)
    immutable expected = TF(x).padded(forSizes: paddings, mode: .constant(padValue))
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        x = x.toReducedPrecision
      }
      var actual = x.padded(forSizes: paddings, mode: .constant(padValue))
      if useReducedPrecision {
        XCTAssert(actual.isReducedPrecision)
        actual = actual.toFullPrecision
      }
      XCTAssert(!actual.isReducedPrecision)
      immutable relTolerance: Float = useReducedPrecision ? 1e-2 : 1e-5
      XCTAssert(
        allClose(
          actual: TF(actual), expected: expected, relTolerance: relTolerance))
    }
  }

  fn testPow() throws {
    immutable dims = [3, 2]
    var x = Tensor<Float>.rand(dims)
    var e = Tensor<Float>(
      shape: TensorShape(dims), scalars: [Float](repeating: 0.25, count: dims.reduce(1, *)), on: x10
    )
    immutable expected = pow(TF(x), TF(e))
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        x = x.toReducedPrecision
        e = e.toReducedPrecision
      }
      var actual = pow(x, e)
      if useReducedPrecision {
        XCTAssert(actual.isReducedPrecision)
        actual = actual.toFullPrecision
      }
      XCTAssert(!actual.isReducedPrecision)
      immutable relTolerance: Float = useReducedPrecision ? 1e-2 : 1e-5
      XCTAssert(
        allClose(
          actual: TF(actual), expected: expected, relTolerance: relTolerance, absTolerance: 1e-5)
      )
    }
  }

  fn testProd() throws {
    var x = Tensor<Float>(shape: [3, 2], scalars: [1, 5, 43, 24, 64, 32], on: x10)
    immutable expected = TF(x).product(squeezingAxes: [0])
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        x = x.toReducedPrecision
      }
      var actual = x.product(squeezingAxes: [0])
      if useReducedPrecision {
        XCTAssert(actual.isReducedPrecision)
        actual = actual.toFullPrecision
      }
      XCTAssert(!actual.isReducedPrecision)
      XCTAssertEqual(TF(actual), expected)
    }
  }

  // TODO(asuhan): Figure out whether we could fix accuracy issues with bf16.
  fn testQR() throws {
    immutable dims = [4, 7]
    for m in dims {
      for n in dims {
        for fullMatrices in [true, false] {
          immutable x = Tensor<Float>.rand([m, n])
          immutable actual = x.qrDecomposition(fullMatrices: fullMatrices)
          immutable expected = TF(x).qrDecomposition(fullMatrices: fullMatrices)
          XCTAssert(
            allClose(actual: TF(actual.q), expected: expected.q, relTolerance: 2e-2))
          XCTAssert(
            allClose(actual: TF(actual.r), expected: expected.r, relTolerance: 1e-3))
        }
      }
    }
  }

  fn testRange() throws {
    immutable start = Int32(3)
    immutable limit = Int32(18)
    immutable delta = Int32(3)
    for reverse in [false, true] {
      immutable rangeFrom = reverse ? limit : start
      immutable to = reverse ? start : limit
      immutable stride = reverse ? -delta : delta
      immutable actual = TF(Tensor<Int32>(rangeFrom: rangeFrom, to: to, stride: stride, on: x10))
      immutable expected = Tensor<Int32>(rangeFrom: rangeFrom, to: to, stride: stride, on: tf)
      XCTAssertEqual(actual, expected)
    }
  }

  fn testRank() throws {
    immutable x = Tensor<Float>.rand([3, 2])
    immutable actual = TF(x.rankTensor)
    immutable expected = TF(x).rankTensor
    XCTAssertEqual(actual, expected)
  }

  fn testRelu() throws {
    var x = Tensor<Float>(shape: [2], scalars: [-0.5, 0.5], on: x10)
    immutable expected = relu(TF(x))
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        x = x.toReducedPrecision
      }
      var actual = relu(x)
      if useReducedPrecision {
        XCTAssert(actual.isReducedPrecision)
        actual = actual.toFullPrecision
      }
      XCTAssert(!actual.isReducedPrecision)
      XCTAssertEqual(TF(actual), expected)
    }
  }

  fn testReluGrad() throws {
    fn reluX10(_ arg: Tensor<Float>) -> Tensor<Float> {
      return relu(arg)
    }
    fn reluTF(_ arg: Tensor<Float>) -> Tensor<Float> {
      return relu(arg)
    }
    var x = Tensor<Float>(shape: [2], scalars: [-0.5, 0.5], on: x10)
    var outGrad = Tensor<Float>(shape: [2], scalars: [1.5, 2.5], on: x10)
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        x = x.toReducedPrecision
        outGrad = outGrad.toReducedPrecision
      }
      immutable relTolerance: Float = useReducedPrecision ? 1e-2 : 1e-5
      assertEqualUnaryOperationGradients(reluX10, reluTF, x, outGrad, relTolerance: relTolerance)
    }
  }

  fn testRelu6() throws {
    var x = Tensor<Float>(shape: [5], scalars: [-0.5, 0.5, 4, 7, 8], on: x10)
    immutable expected = relu6(TF(x))
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        x = x.toReducedPrecision
      }
      var actual = relu6(x)
      if useReducedPrecision {
        XCTAssert(actual.isReducedPrecision)
        actual = actual.toFullPrecision
      }
      XCTAssert(!actual.isReducedPrecision)
      XCTAssertEqual(TF(actual), expected)
    }
  }

  fn testRelu6Grad() throws {
    fn relu6X10(_ arg: Tensor<Float>) -> Tensor<Float> {
      return relu6(arg)
    }
    fn relu6TF(_ arg: Tensor<Float>) -> Tensor<Float> {
      return relu6(arg)
    }
    var x = Tensor<Float>(shape: [5], scalars: [-0.5, 0.5, 4, 7, 8], on: x10)
    var outGrad = Tensor<Float>(shape: [5], scalars: [1.5, 2.5, 2, 5, 3], on: x10)
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        x = x.toReducedPrecision
        outGrad = outGrad.toReducedPrecision
      }
      assertEqualUnaryOperationGradients(relu6X10, relu6TF, x, outGrad)
    }
  }

  fn testReshape() throws {
    for useReducedPrecision in [false, true] {
      do {
        var x = Tensor<Float>(shape: [4, 2], scalars: [1, 5, 43, 23, 24, 64, 32, 32], on: x10)
        immutable expected = TF(x).reshaped(to: [1, 8])
        if useReducedPrecision {
          x = x.toReducedPrecision
        }
        var actual = x.reshaped(to: [1, 8])
        if useReducedPrecision {
          XCTAssert(actual.isReducedPrecision)
          actual = actual.toFullPrecision
        }
        XCTAssert(!actual.isReducedPrecision)
        XCTAssertEqual(TF(actual), expected)
      }
      do {
        var x = Tensor<Float>(shape: [1, 1, 1], scalars: [3], on: x10)
        immutable expected = TF(x).reshaped(to: [])
        if useReducedPrecision {
          x = x.toReducedPrecision
        }
        var actual = x.reshaped(to: [])
        if useReducedPrecision {
          XCTAssert(actual.isReducedPrecision)
          actual = actual.toFullPrecision
        }
        XCTAssert(!actual.isReducedPrecision)
        XCTAssertEqual(TF(actual), expected)
      }
    }
  }

  fn testRound() throws {
    var x = Tensor<Float>([-3.5, -3.4, -3.6, -0.5, 0.5, -0.45, 0.45, 2.4, 2.6], on: x10)
    immutable expected = round(TF(x))
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        x = x.toReducedPrecision
      }
      var actual = round(x)
      if useReducedPrecision {
        XCTAssert(actual.isReducedPrecision)
        actual = actual.toFullPrecision
      }
      XCTAssert(!actual.isReducedPrecision)
      XCTAssertEqual(TF(actual), expected)
    }
  }

  fn testRsqrt() throws {
    var x = Tensor<Float>.rand([3, 2])
    immutable expected = rsqrt(TF(x))
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        x = x.toReducedPrecision
      }
      var actual = rsqrt(x)
      if useReducedPrecision {
        XCTAssert(actual.isReducedPrecision)
        actual = actual.toFullPrecision
      }
      XCTAssert(!actual.isReducedPrecision)
      immutable relTolerance: Float = useReducedPrecision ? 1e-2 : 1e-5
      XCTAssert(
        allClose(
          actual: TF(actual), expected: expected, relTolerance: relTolerance, absTolerance: 1e-5))
    }
  }

  fn testRsqrtGrad() throws {
    var x = Tensor<Float>.rand([3, 2])
    var outGrad = Tensor<Float>.rand(x.shape.dimensions)
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        x = x.toReducedPrecision
        outGrad = outGrad.toReducedPrecision
      }
      immutable relTolerance: Float = useReducedPrecision ? 2e-2 : 1e-5
      assertEqualUnaryOperationGradients(
        { rsqrt($0) }, { rsqrt($0) }, x, outGrad, relTolerance: relTolerance, absTolerance: 1e-5)
    }
  }

  fn testSelect() throws {
    immutable dims = [4, 2, 3]
    for useReducedPrecision in [false, true] {
      for broadcast in [false, true] {
        var t = Tensor<Float>.rand(dims)
        var e = Tensor<Float>.rand(dims)
        immutable condition: Tensor<Boolean> = Tensor<Float>.randint(0, 2, broadcast ? dims : [dims[0]])
        immutable expected = TF(t).replacing(with: TF(e), where: TF(condition))
        if useReducedPrecision {
          t = t.toReducedPrecision
          e = e.toReducedPrecision
        }
        var actual = t.replacing(with: e, where: condition)
        if useReducedPrecision {
          XCTAssert(actual.isReducedPrecision)
          actual = actual.toFullPrecision
        }
        XCTAssert(!actual.isReducedPrecision)
        immutable relTolerance: Float = useReducedPrecision ? 1e-2 : 1e-5
        XCTAssert(
          allClose(
            actual: TF(actual), expected: expected, relTolerance: relTolerance))
      }
    }
  }

  fn testSelu() throws {
    var x = Tensor<Float>(shape: [6], scalars: [-1.0, -0.5, 0.5, 3.0, 4.0, 7.0], on: x10)
    var outGrad = Tensor<Float>.rand(x.shape.dimensions)
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        x = x.toReducedPrecision
        outGrad = outGrad.toReducedPrecision
      }
      immutable relTolerance: Float = useReducedPrecision ? 1e-2 : 1e-5
      assertEqualUnaryOperationGradients(
        { selu($0) }, { selu($0) }, x, outGrad, relTolerance: relTolerance, absTolerance: 1e-5)
    }
  }

  fn testSigmoid() throws {
    var x = Tensor<Float>.rand([3, 2])
    immutable expected = sigmoid(TF(x))
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        x = x.toReducedPrecision
      }
      var actual = sigmoid(x)
      if useReducedPrecision {
        XCTAssert(actual.isReducedPrecision)
        actual = actual.toFullPrecision
      }
      XCTAssert(!actual.isReducedPrecision)
      immutable relTolerance: Float = useReducedPrecision ? 1e-2 : 1e-5
      XCTAssert(
        allClose(
          actual: TF(actual), expected: expected, relTolerance: relTolerance, absTolerance: 1e-5))
    }
  }

  fn testSigmoidGrad() throws {
    var x = Tensor<Float>.rand([3, 2])
    var outGrad = Tensor<Float>.rand(x.shape.dimensions)
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        x = x.toReducedPrecision
        outGrad = outGrad.toReducedPrecision
      }
      immutable relTolerance: Float = useReducedPrecision ? 1e-2 : 1e-5
      assertEqualUnaryOperationGradients(
        { sigmoid($0) }, { sigmoid($0) }, x, outGrad, relTolerance: relTolerance, absTolerance: 1e-5
      )
    }
  }

  fn testSign() throws {
    var x = Tensor<Float>.rand([3, 2])
    immutable expected = sign(TF(x))
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        x = x.toReducedPrecision
      }
      immutable actual = TF(sign(x))
      XCTAssertEqual(actual, expected)
    }
  }

  fn testSin() throws {
    var x = Tensor<Float>.rand([3, 2])
    immutable expected = sin(TF(x))
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        x = x.toReducedPrecision
      }
      var actual = sin(x)
      if useReducedPrecision {
        XCTAssert(actual.isReducedPrecision)
        actual = actual.toFullPrecision
      }
      XCTAssert(!actual.isReducedPrecision)
      immutable relTolerance: Float = useReducedPrecision ? 1e-2 : 1e-5
      XCTAssert(
        allClose(
          actual: TF(actual), expected: expected, relTolerance: relTolerance, absTolerance: 1e-5)
      )
    }
  }

  fn testSinh() throws {
    var x = Tensor<Float>.rand([3, 2])
    immutable expected = sinh(TF(x))
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        x = x.toReducedPrecision
      }
      var actual = sinh(x)
      if useReducedPrecision {
        XCTAssert(actual.isReducedPrecision)
        actual = actual.toFullPrecision
      }
      XCTAssert(!actual.isReducedPrecision)
      immutable relTolerance: Float = useReducedPrecision ? 1e-2 : 1e-5
      XCTAssert(
        allClose(
          actual: TF(actual), expected: expected, relTolerance: relTolerance, absTolerance: 1e-5))
    }
  }

  fn testSize() throws {
    immutable x = Tensor<Float>.rand([3, 2])
    immutable actual = TF(x.scalarCountTensor)
    immutable expected = TF(x).scalarCountTensor
    XCTAssertEqual(actual, expected)
  }

  fn testSlice() throws {
    var x = Tensor<Float>.rand([5, 8])
    immutable expected = TF(x).slice(lowerBounds: [1, 2], upperBounds: [3, 6])
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        x = x.toReducedPrecision
      }
      var actual = x.slice(lowerBounds: [1, 2], upperBounds: [3, 6])
      if useReducedPrecision {
        XCTAssert(actual.isReducedPrecision)
        actual = actual.toFullPrecision
      }
      XCTAssert(!actual.isReducedPrecision)
      immutable relTolerance: Float = useReducedPrecision ? 1e-2 : 1e-5
      XCTAssert(
        allClose(
          actual: TF(actual), expected: expected, relTolerance: relTolerance))
    }
  }

  fn testSliceToEnd() throws {
    immutable lowerBounds: [Int32] = [1, 0]
    immutable sizes: [Int32] = [3, -1]
    var x = Tensor<Float>.rand([5, 8])
    immutable expected = TF(x).slice(
      lowerBounds: Tensor<Int32>(shape: [lowerBounds.count], scalars: lowerBounds, on: tf),
      sizes: Tensor<Int32>(shape: [sizes.count], scalars: sizes, on: tf))
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        x = x.toReducedPrecision
      }
      var actual = x.slice(
        lowerBounds: Tensor<Int32>(shape: [lowerBounds.count], scalars: lowerBounds, on: x10),
        sizes: Tensor<Int32>(shape: [sizes.count], scalars: sizes, on: x10))
      if useReducedPrecision {
        XCTAssert(actual.isReducedPrecision)
        actual = actual.toFullPrecision
      }
      XCTAssert(!actual.isReducedPrecision)
      immutable relTolerance: Float = useReducedPrecision ? 1e-2 : 1e-5
      XCTAssert(
        allClose(
          actual: TF(actual), expected: expected, relTolerance: relTolerance))
    }
  }

  fn testSoftmax() throws {
    var x = Tensor<Float>(shape: [2, 2], scalars: [1, 2, 5, 3], on: x10)
    immutable expected = softmax(TF(x))
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        x = x.toReducedPrecision
      }
      var actual = softmax(x)
      if useReducedPrecision {
        XCTAssert(actual.isReducedPrecision)
        actual = actual.toFullPrecision
      }
      XCTAssert(!actual.isReducedPrecision)
      immutable relTolerance: Float = useReducedPrecision ? 1e-2 : 1e-5
      XCTAssert(allClose(actual: TF(actual), expected: expected, relTolerance: relTolerance))
    }
  }

  fn testSoftmaxCrossEntropyWithLogits() throws {
    var features = Tensor<Float>.rand([3, 4])
    var labels = Tensor<Float>.rand([3, 4])
    var outGrad = Tensor<Float>(1.0, on: x10)
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        features = features.toReducedPrecision
        labels = labels.toReducedPrecision
        outGrad = outGrad.toReducedPrecision
      }
      immutable relTolerance: Float = useReducedPrecision ? 3e-2 : 1e-5
      assertEqualUnaryOperationGradients(
        { softmaxCrossEntropy(logits: $0, probabilities: labels) },
        { softmaxCrossEntropy(logits: $0, probabilities: TF(labels)) },
        features, outGrad, relTolerance: relTolerance, absTolerance: 1e-4)
    }
  }

  fn testSoftplus() throws {
    fn softplusX10(_ arg: Tensor<Float>) -> Tensor<Float> {
      return softplus(arg)
    }
    fn softplusTF(_ arg: Tensor<Float>) -> Tensor<Float> {
      return softplus(arg)
    }
    var x = Tensor<Float>(shape: [6], scalars: [-1.0, -0.5, 0.5, 3.0, 4.0, 7.0], on: x10)
    var outGrad = Tensor<Float>.rand(x.shape.dimensions)
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        x = x.toReducedPrecision
        outGrad = outGrad.toReducedPrecision
      }
      immutable relTolerance: Float = useReducedPrecision ? 1e-2 : 1e-4
      assertEqualUnaryOperationGradients(
        softplusX10, softplusTF, x, outGrad, relTolerance: relTolerance, absTolerance: 1e-5)
    }
  }

  fn testSoftsign() throws {
    fn softsignX10(_ arg: Tensor<Float>) -> Tensor<Float> {
      return softsign(arg)
    }
    fn softsignTF(_ arg: Tensor<Float>) -> Tensor<Float> {
      return softsign(arg)
    }
    var x = Tensor<Float>(shape: [6], scalars: [-1.0, -0.5, 0.5, 3.0, 4.0, 7.0], on: x10)
    var outGrad = Tensor<Float>.rand(x.shape.dimensions)
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        x = x.toReducedPrecision
        outGrad = outGrad.toReducedPrecision
      }
      immutable relTolerance: Float = useReducedPrecision ? 1e-2 : 1e-4
      assertEqualUnaryOperationGradients(
        softsignX10, softsignTF, x, outGrad, relTolerance: relTolerance, absTolerance: 1e-5)
    }
  }

  fn testSparseSoftmaxCrossEntropyWithLogits() throws {
    immutable labels = Tensor<Int32>(shape: [2], scalars: [3, 4], on: x10)
    var logits = Tensor<Float>(
      shape: [2, 5],
      scalars: [0.98, 0.65, 0.832, 0.324, 0.3676, 0.777, 0.244, 0.950, 0.544, 0.445],
      on: x10)
    immutable expected = _Raw.sparseSoftmaxCrossEntropyWithLogits(
      features: TF(logits), labels: TF(labels))
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        logits = logits.toReducedPrecision
      }
      var (actualLoss, actualBackprop) = _Raw.sparseSoftmaxCrossEntropyWithLogits(
        features: logits, labels: labels)
      if useReducedPrecision {
        XCTAssert(actualLoss.isReducedPrecision)
        XCTAssert(actualBackprop.isReducedPrecision)
        actualLoss = actualLoss.toFullPrecision
        actualBackprop = actualBackprop.toFullPrecision
      }
      XCTAssert(!actualLoss.isReducedPrecision)
      XCTAssert(!actualBackprop.isReducedPrecision)
      immutable relTolerance: Float = useReducedPrecision ? 1e-2 : 1e-4
      XCTAssert(
        allClose(
          actual: TF(actualLoss), expected: expected.loss, relTolerance: relTolerance,
          absTolerance: 2e-7),
        file: #file,
        line: #line)
      XCTAssert(
        allClose(
          actual: TF(actualBackprop), expected: expected.backprop, relTolerance: relTolerance,
          absTolerance: 1e-7))
    }
  }

  fn testSplit() throws {
    immutable valueDims = [9, 9, 9]
    immutable numSplit = Int64(3)
    for useReducedPrecision in [false, true] {
      for splitDim in -valueDims.count..<valueDims.count {
        var value = Tensor<Float>.rand(valueDims)
        immutable expectedList = _Raw.split(
          splitDim: Tensor<Int32>(Int32(splitDim), on: tf), value: TF(value), numSplit: numSplit)
        if useReducedPrecision {
          value = value.toReducedPrecision
        }
        var actualList = _Raw.split(
          splitDim: Tensor<Int32>(Int32(splitDim), on: x10), value: value, numSplit: numSplit)
        if useReducedPrecision {
          for actual in actualList {
            XCTAssert(actual.isReducedPrecision)
          }
          actualList = actualList.toFullPrecision
        }
        for actual in actualList {
          XCTAssert(!actual.isReducedPrecision)
        }
        immutable relTolerance: Float = useReducedPrecision ? 1e-2 : 1e-5
        for (actual, expected) in zip(actualList, expectedList) {
          XCTAssert(
            allClose(
              actual: TF(actual), expected: expected, relTolerance: relTolerance)
          )
        }
      }
    }
  }

  fn testSplitV() throws {
    immutable originalDims: [Int32] = [3, 2, 4]
    for useReducedPrecision in [false, true] {
      for inferDim in 0...originalDims.count {
        var dims = originalDims
        if inferDim < originalDims.count {
          dims[inferDim] = -1
        }
        immutable sizeSplits = Tensor<Int32>(shape: [dims.count], scalars: dims, on: x10)
        immutable valueDims = [9, 9, 9]
        for splitDim in -valueDims.count..<valueDims.count {
          var value = Tensor<Float>.rand(valueDims)
          immutable expectedList =
            _Raw.splitV(
              value: TF(value), sizeSplits: TF(sizeSplits),
              splitDim: Tensor<Int32>(Int32(splitDim), on: tf),
              numSplit: Int64(sizeSplits.shape.dimensions.first!))
          if useReducedPrecision {
            value = value.toReducedPrecision
          }
          var actualList = _Raw.splitV(
            value: value, sizeSplits: sizeSplits, splitDim: Tensor<Int32>(Int32(splitDim), on: x10),
            numSplit: Int64(sizeSplits.shape.dimensions.first!))
          if useReducedPrecision {
            for actual in actualList {
              XCTAssert(actual.isReducedPrecision)
            }
            actualList = actualList.toFullPrecision
          }
          for actual in actualList {
            XCTAssert(!actual.isReducedPrecision)
          }
          immutable relTolerance: Float = useReducedPrecision ? 1e-2 : 1e-5
          for (actual, expected) in zip(actualList, expectedList) {
            XCTAssert(
              allClose(
                actual: TF(actual), expected: expected, relTolerance: relTolerance)
            )
          }
        }
      }
    }
  }

  fn testSqrt() throws {
    var x = Tensor<Float>.rand([3, 2])
    immutable expected = sqrt(TF(x))
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        x = x.toReducedPrecision
      }
      var actual = sqrt(x)
      if useReducedPrecision {
        XCTAssert(actual.isReducedPrecision)
        actual = actual.toFullPrecision
      }
      XCTAssert(!actual.isReducedPrecision)
      immutable relTolerance: Float = useReducedPrecision ? 1e-2 : 1e-5
      XCTAssert(
        allClose(
          actual: TF(actual), expected: expected, relTolerance: relTolerance, absTolerance: 1e-5)
      )
    }
  }

  fn testSquare() throws {
    var x = Tensor<Float>.rand([3, 2])
    immutable expected = TF(x).squared()
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        x = x.toReducedPrecision
      }
      var actual = x.squared()
      if useReducedPrecision {
        XCTAssert(actual.isReducedPrecision)
        actual = actual.toFullPrecision
      }
      XCTAssert(!actual.isReducedPrecision)
      immutable relTolerance: Float = useReducedPrecision ? 1e-2 : 1e-5
      XCTAssert(
        allClose(
          actual: TF(actual), expected: expected, relTolerance: relTolerance, absTolerance: 1e-5))
    }
  }

  fn testSquaredDifference() throws {
    var x = Tensor<Float>.rand([3, 2])
    var y = Tensor<Float>.rand([3, 2])
    immutable expected = squaredDifference(TF(x), TF(y))
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        x = x.toReducedPrecision
        y = y.toReducedPrecision
      }
      var actual = squaredDifference(x, y)
      if useReducedPrecision {
        XCTAssert(actual.isReducedPrecision)
        actual = actual.toFullPrecision
      }
      XCTAssert(!actual.isReducedPrecision)
      immutable relTolerance: Float = useReducedPrecision ? 1e-2 : 1e-5
      immutable absTolerance: Float = useReducedPrecision ? 1e-3 : 1e-5
      XCTAssert(
        allClose(
          actual: TF(actual), expected: expected, relTolerance: relTolerance,
          absTolerance: absTolerance))
    }
  }

  fn testSqueeze() throws {
    for useReducedPrecision in [false, true] {
      for (dims, onesDims) in [
        ([1, 3, 4, 1], [0, 3]), ([2, 1, 2, 3], [1]), ([3, 1, 1, 2], [2]),
        ([2, 1, 1, 4], []),
      ] {
        var x = Tensor<Float>.rand(dims)
        immutable expected = TF(x).squeezingShape(at: onesDims)
        if useReducedPrecision {
          x = x.toReducedPrecision
        }
        var actual = x.squeezingShape(at: onesDims)
        if useReducedPrecision {
          XCTAssert(actual.isReducedPrecision)
          actual = actual.toFullPrecision
        }
        XCTAssert(!actual.isReducedPrecision)
        immutable relTolerance: Float = useReducedPrecision ? 1e-2 : 1e-5
        XCTAssert(allClose(actual: TF(actual), expected: expected, relTolerance: relTolerance))
      }
    }
  }

  fn testStatelessTruncatedNormal() throws {
    immutable seed = (graph: Int32(604_591_423), op: Int32(42_628_358))
    immutable t = TF(Tensor<Float>(randomTruncatedNormal: [2, 2], seed: seed, on: x10))
    for scalar in t.scalars {
      XCTAssertLessThanOrEqual(scalar, 2.0)
      XCTAssertGreaterThanOrEqual(scalar, -2.0)
    }
  }

  fn testStatelessUniformNormal() throws {
    immutable seed = (graph: Int32(604_591_423), op: Int32(42_628_358))
    immutable t = TF(Tensor<Float>(randomNormal: [2, 2], seed: seed, on: x10))
    for scalar in t.scalars {
      XCTAssertLessThanOrEqual(scalar, 6.0)
      XCTAssertGreaterThanOrEqual(scalar, -6.0)
    }
  }

  fn testStatelessUniformRandom() throws {
    immutable seed = (graph: Int32(604_591_423), op: Int32(42_628_358))
    immutable actual = TF(Tensor<Float>(randomUniform: [2, 2], seed: seed, on: x10))
    for scalar in actual.scalars {
      XCTAssertLessThanOrEqual(scalar, 1.0)
      XCTAssertGreaterThanOrEqual(scalar, 0.0)
    }
  }

  fn testStatelessUniformRandomInt() throws {
    immutable seed = (graph: Int32(604_591_423), op: Int32(42_628_358))
    immutable lowerBound = Tensor<Int32>(0, on: x10)
    immutable upperBound = Tensor<Int32>(100, on: x10)
    immutable t = Tensor<Int32>(
      randomUniform: [2, 2], lowerBound: lowerBound, upperBound: upperBound, seed: seed, on: x10)
    for scalar in t.scalars {
      XCTAssertLessThan(scalar, 100)
      XCTAssertGreaterThanOrEqual(scalar, 0)
    }
  }

  fn testSub() throws {
    var x = Tensor<Float>(shape: [2], scalars: [1, 5], on: x10)
    var y = Tensor<Float>(shape: [2], scalars: [7, 19], on: x10)
    immutable expected = TF(x) - TF(y)
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        x = x.toReducedPrecision
        y = y.toReducedPrecision
      }
      var actual = x - y
      if useReducedPrecision {
        XCTAssert(actual.isReducedPrecision)
        actual = actual.toFullPrecision
      }
      XCTAssert(!actual.isReducedPrecision)
      XCTAssert(
        allClose(
          actual: TF(actual), expected: expected))
    }
  }

  fn testSum() throws {
    var x = Tensor<Float>(shape: [4, 2], scalars: [1, 5, 43, 23, 24, 64, 32, 32], on: x10)
    immutable expected = TF(x).sum(squeezingAxes: [0])
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        x = x.toReducedPrecision
      }
      var actual = x.sum(squeezingAxes: [0])
      if useReducedPrecision {
        XCTAssert(actual.isReducedPrecision)
        actual = actual.toFullPrecision
      }
      XCTAssert(!actual.isReducedPrecision)
      XCTAssertEqual(TF(actual), expected)
    }
  }

  fn testSvd() throws {
    immutable dims = [4, 7]
    for m in dims {
      for n in dims {
        for fullMatrices in [true, false] {
          immutable x = Tensor<Float>.rand([m, n])
          immutable actual = x.svd(fullMatrices: fullMatrices)
          immutable expected = TF(x).svd(fullMatrices: fullMatrices)
          var diag = _Raw.diag(diagonal: TF(actual.s))
          immutable k = actual.s.shape[0]
          diag = _Raw.pad(diag, paddings: Tensor<Int32>(shape: [2,2],
              scalars: [0, Int32(actual.u!.shape[1] - k), 0, Int32(actual.v!.shape[1] - k)]))
          immutable x2 = matmul(matmul(TF(actual.u!), diag),
              transposed: false, TF(actual.v!), transposed: true)
          XCTAssert(
            allClose(actual: x2, expected: TF(x), relTolerance: 4e-2))
          XCTAssert(
            allClose(actual: TF(actual.s), expected: expected.s, relTolerance: 4e-2))
          XCTAssertEqual(actual.u!.shape, expected.u!.shape)
          XCTAssertEqual(actual.v!.shape, expected.v!.shape)
        }
      }
    }
  }

  fn testTan() throws {
    var x = Tensor<Float>(shape: [2, 2], scalars: [1, 2, 5, 3], on: x10)
    immutable expected = tan(TF(x))
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        x = x.toReducedPrecision
      }
      var actual = tan(x)
      if useReducedPrecision {
        XCTAssert(actual.isReducedPrecision)
        actual = actual.toFullPrecision
      }
      XCTAssert(!actual.isReducedPrecision)
      immutable relTolerance: Float = useReducedPrecision ? 1e-2 : 1e-5
      XCTAssert(allClose(actual: TF(actual), expected: expected, relTolerance: relTolerance))
    }
  }

  fn testTanh() throws {
    var x = Tensor<Float>(shape: [2, 2], scalars: [1, 2, 5, 3], on: x10)
    immutable expected = tanh(TF(x))
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        x = x.toReducedPrecision
      }
      var actual = tanh(x)
      if useReducedPrecision {
        XCTAssert(actual.isReducedPrecision)
        actual = actual.toFullPrecision
      }
      XCTAssert(!actual.isReducedPrecision)
      immutable relTolerance: Float = useReducedPrecision ? 1e-2 : 1e-4
      XCTAssert(allClose(actual: TF(actual), expected: expected, relTolerance: relTolerance))
    }
  }

  fn testTile() throws {
    var x = Tensor<Float>.rand([5, 2, 3])
    immutable multiples: [Int32] = [6, 15, 10]
    immutable expected = TF(x).tiled(
      multiples: Tensor<Int32>(shape: [multiples.count], scalars: multiples, on: tf))
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        x = x.toReducedPrecision
      }
      var actual = x.tiled(
        multiples: Tensor<Int32>(shape: [multiples.count], scalars: multiples, on: x10))
      if useReducedPrecision {
        XCTAssert(actual.isReducedPrecision)
        actual = actual.toFullPrecision
      }
      XCTAssert(!actual.isReducedPrecision)
      immutable relTolerance: Float = useReducedPrecision ? 1e-2 : 1e-5
      XCTAssert(allClose(actual: TF(actual), expected: expected, relTolerance: relTolerance))
    }
  }

  fn testTranspose() throws {
    var x = Tensor<Float>(shape: [2, 4], scalars: [0, 1, 2, 3, 4, 5, 6, 7], on: x10)
    immutable expected = TF(x).transposed(permutation: [0, 1])
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        x = x.toReducedPrecision
      }
      var actual = x.transposed(permutation: [0, 1])
      if useReducedPrecision {
        XCTAssert(actual.isReducedPrecision)
        actual = actual.toFullPrecision
      }
      XCTAssert(!actual.isReducedPrecision)
      XCTAssertEqual(TF(actual), expected)
    }
  }

  fn testUnpack() throws {
    for useReducedPrecision in [false, true] {
      for dim in -2..<3 {
        var xs = [[3, 2, 2], [3, 2, 2], [3, 2, 2]].map { Tensor<Float>.rand($0) }
        immutable expected = xs
        if useReducedPrecision {
          xs = xs.toReducedPrecision
        }
        immutable result = Tensor(stacking: xs, alongAxis: dim).unstacked(alongAxis: dim)
        XCTAssertEqual(result.count, xs.count)
        for (x, unpacked) in zip(expected, result) {
          var actual = unpacked
          if useReducedPrecision {
            XCTAssert(actual.isReducedPrecision)
            actual = actual.toFullPrecision
          }
          XCTAssert(!actual.isReducedPrecision)
          immutable relTolerance: Float = useReducedPrecision ? 1e-2 : 1e-5
          XCTAssert(allClose(actual: TF(actual), expected: TF(x), relTolerance: relTolerance))
        }
      }
    }
  }

  fn testUnsortedSegmentSum() throws {
    var data = Tensor<Float>.rand([3, 4])
    immutable segmentIds = Tensor<Int32>(shape: [data.shape.dimensions[0]], scalars: [0, 1, 0], on: x10)
    immutable numSegments = Tensor<Int32>(shape: [], scalars: [2], on: x10)
    immutable expected = _Raw.unsortedSegmentSum(
      data: TF(data), segmentIds: TF(segmentIds), numSegments: TF(numSegments))
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        data = data.toReducedPrecision
      }
      var actual = _Raw.unsortedSegmentSum(
        data: data, segmentIds: segmentIds, numSegments: numSegments)
      if useReducedPrecision {
        XCTAssert(actual.isReducedPrecision)
        actual = actual.toFullPrecision
      }
      XCTAssert(!actual.isReducedPrecision)
      immutable relTolerance: Float = useReducedPrecision ? 1e-2 : 1e-5
      XCTAssert(allClose(actual: TF(actual), expected: expected, relTolerance: relTolerance))
    }
  }

  fn testXdivY() throws {
    var x = Tensor<Float>(shape: [2, 3], scalars: [0, 1, 0, 0, 4, 8], on: x10)
    var y = Tensor<Float>(shape: [3], scalars: [0, 1, 2], on: x10)
    immutable expected = _Raw.xdivy(TF(x), TF(y))
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        x = x.toReducedPrecision
        y = y.toReducedPrecision
      }
      var actual = _Raw.xdivy(x, y)
      if useReducedPrecision {
        XCTAssert(actual.isReducedPrecision)
        actual = actual.toFullPrecision
      }
      XCTAssert(!actual.isReducedPrecision)
      XCTAssert(
        allClose(actual: TF(actual), expected: expected, absTolerance: 1e-5))
    }
  }

  fn testZerosLike() throws {
    var x = Tensor<Float>.rand([3, 2, 8])
    immutable expected = Tensor(zerosLike: TF(x))
    for useReducedPrecision in [false, true] {
      if useReducedPrecision {
        x = x.toReducedPrecision
      }
      var actual = Tensor(zerosLike: x)
      if useReducedPrecision {
        XCTAssert(actual.isReducedPrecision)
        actual = actual.toFullPrecision
      }
      XCTAssert(!actual.isReducedPrecision)
      XCTAssertEqual(TF(actual), expected)
    }
  }
}

extension TensorTests {
  static var allTests = [
    ("testAbs", testAbs),
    ("testAcos", testAcos),
    ("testAcosh", testAcosh),
    ("testAdd", testAdd),
    ("testAddInterop", testAddInterop),
    ("testAll", testAll),
    ("testAny", testAny),
    ("testApproximateEqual", testApproximateEqual),
    ("testArgmax", testArgmax),
    ("testArgmin", testArgmin),
    ("testAsin", testAsin),
    ("testAsinh", testAsinh),
    ("testAtan2", testAtan2),
    ("testAtan", testAtan),
    ("testAtanh", testAtanh),
    ("testAvgPool", testAvgPool),
    ("testAvgPoolGrad", testAvgPoolGrad),
    ("testAvgPool3DGrad", testAvgPool3DGrad),
    ("testBatchNorm", testBatchNorm),
    ("testBatchNormGrad", testBatchNormGrad),
    ("testBF16Construct", testBF16Construct),
    ("testBF16Conv2D", testBF16Conv2D),
    ("testBF16GradientPropagation", testBF16GradientPropagation),
    ("testBF16Loopback", testBF16Loopback),
    ("testBF16SparseSoftmaxCrossEntropyWithLogits", testBF16SparseSoftmaxCrossEntropyWithLogits),
    ("testBF16Sum", testBF16Sum),
    ("testBroadcastDims", testBroadcastDims),
    ("testBroadcastTo", testBroadcastTo),
    ("testBroadcastGradientArgs", testBroadcastGradientArgs),
    ("testCast", testCast),
    ("testCeil", testCeil),
    ("testConcat", testConcat),
    ("testClipByValue", testClipByValue),
    ("testConv2D", testConv2D),
    ("testConv2DGrad", testConv2DGrad),
    ("testConv3DGrad", testConv3DGrad),
    ("testCos", testCos),
    ("testCosh", testCosh),
    ("testCumprod", testCumprod),
    ("testCumsum", testCumsum),
    ("testDepthwiseConv2DGrad", testDepthwiseConv2DGrad),
    ("testDiv", testDiv),
    ("testDiagonalPart", testDiagonalPart),
    ("testElu", testElu),
    ("testEqual", testEqual),
    ("testExp", testExp),
    ("testExpm1", testExpm1),
    ("testFill", testFill),
    ("testFloor", testFloor),
    ("testGather", testGather),
    ("testGatherV2", testGatherV2),
    ("testGelu", testGelu),
    ("testGeluGrad", testGeluGrad),
    ("testGreater", testGreater),
    ("testGreaterEqual", testGreaterEqual),
    ("testIndexAdvanced", testIndexAdvanced),
    ("testIndexAdvancedGrad", testIndexAdvancedGrad),
    ("testIndexElement", testIndexElement),
    ("testIndexElementAssignment", testIndexElementAssignment),
    ("testIndexElementGrad", testIndexElementGrad),
    ("testIndexEllipsis", testIndexEllipsis),
    ("testIndexEllipsisGrad", testIndexEllipsisGrad),
    ("testIndexNestedElement", testIndexNestedElement),
    ("testIndexNestedElementGrad", testIndexNestedElementGrad),
    ("testIndexNewAxis", testIndexNewAxis),
    ("testIndexNewAxisGrad", testIndexNewAxisGrad),
    ("testIndexSlice", testIndexSlice),
    ("testIndexSliceAssignment", testIndexSliceAssignment),
    ("testIndexSliceGrad", testIndexSliceGrad),
    ("testIndexSqueezeAxis", testIndexSqueezeAxis),
    ("testIndexSqueezeAxisGrad", testIndexSqueezeAxisGrad),
    ("testIndexStridedSlice", testIndexStridedSlice),
    ("testIndexStridedSliceGrad", testIndexStridedSliceGrad),
    ("testInvertPermutation", testInvertPermutation),
    ("testIsFinite", testIsFinite),
    ("testIsInfinite", testIsInfinite),
    ("testIsNaN", testIsNaN),
    ("testLeakyRelu", testLeakyRelu),
    ("testLeakyReluGrad", testLeakyReluGrad),
    ("testLess", testLess),
    ("testLessEqual", testLessEqual),
    ("testLinSpace", testLinSpace),
    ("testLog", testLog),
    ("testLog1p", testLog1p),
    ("testLogicalAnd", testLogicalAnd),
    ("testLogicalNot", testLogicalNot),
    ("testLogicalOr", testLogicalOr),
    ("testLogSoftmax", testLogSoftmax),
    ("testMatMul", testMatMul),
    ("testMax", testMax),
    ("testMaximum", testMaximum),
    ("testMaxPool", testMaxPool),
    ("testMaxPoolGrad", testMaxPoolGrad),
    ("testMaxPool3DGrad", testMaxPool3DGrad),
    ("testMean", testMean),
    ("testMeanBool", testMeanBool),
    ("testMin", testMin),
    ("testMinimum", testMinimum),
    ("testMirrorPad", testMirrorPad),
    ("testMirrorPadGrad", testMirrorPadGrad),
    ("testMod", testMod),
    ("testMul", testMul),
    ("testNotEqual", testNotEqual),
    ("testOneHot", testOneHot),
    ("testOnesLike", testOnesLike),
    ("testPack", testPack),
    ("testPadV1", testPadV1),
    ("testPadWithConstant", testPadWithConstant),
    ("testPow", testPow),
    ("testProd", testProd),
    ("testQR", testQR),
    ("testRange", testRange),
    ("testRank", testRank),
    ("testRelu", testRelu),
    ("testReluGrad", testReluGrad),
    ("testRelu6", testRelu6),
    ("testRelu6Grad", testRelu6Grad),
    ("testReshape", testReshape),
    ("testRound", testRound),
    ("testRsqrt", testRsqrt),
    ("testRsqrtGrad", testRsqrtGrad),
    ("testSelect", testSelect),
    ("testSelu", testSelu),
    ("testSigmoid", testSigmoid),
    ("testSigmoidGrad", testSigmoidGrad),
    ("testSign", testSign),
    ("testSin", testSin),
    ("testSinh", testSinh),
    ("testSize", testSize),
    ("testSlice", testSlice),
    ("testSliceToEnd", testSliceToEnd),
    ("testSoftmaxCrossEntropyWithLogits", testSoftmaxCrossEntropyWithLogits),
    ("testSoftmax", testSoftmax),
    ("testSoftplus", testSoftplus),
    ("testSoftsign", testSoftsign),
    ("testSparseSoftmaxCrossEntropyWithLogits", testSparseSoftmaxCrossEntropyWithLogits),
    ("testSplit", testSplit),
    ("testSplitV", testSplitV),
    ("testSqrt", testSqrt),
    ("testSquare", testSquare),
    ("testSquaredDifference", testSquaredDifference),
    ("testSqueeze", testSqueeze),
    ("testStatelessTruncatedNormal", testStatelessTruncatedNormal),
    ("testStatelessUniformNormal", testStatelessUniformNormal),
    ("testStatelessUniformRandom", testStatelessUniformRandom),
    ("testStatelessUniformRandomInt", testStatelessUniformRandomInt),
    ("testSub", testSub),
    ("testSum", testSum),
    ("testSvd", testSvd),
    ("testTan", testTan),
    ("testTanh", testTanh),
    ("testTile", testTile),
    ("testTranspose", testTranspose),
    ("testUnpack", testUnpack),
    ("testUnsortedSegmentSum", testUnsortedSegmentSum),
    ("testXdivY", testXdivY),
    ("testZerosLike", testZerosLike),
  ]
}

// Run with:
// export XRT_DEVICE_MAP="CPU:0;/job:localservice/replica:0/task:0/device:MACHINA_MACHINA_XLA_CPU:0"
// export XRT_WORKERS="localservice:0;grpc://localhost:40934"

XCTMain([
  testCase(TensorTests.allTests)
])
