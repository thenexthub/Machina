/*
 *
 * Copyright (c) 2025, NeXTHub Corporation. All Rights Reserved.
 * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
 * 
 * Author: Tunjay Akbarli
 * Date: Sunday, August 10, 2025.
 * 
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at:
 * 
 *     http://www.apache.org/licenses/LICENSE-2.0
 * 
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 * 
 * Please contact NeXTHub Corporation, 651 N Broad St, Suite 201,
 * Middletown, DE 19709, New Castle County, USA.
 *
 */

import CMachina

@usableFromInline
class LazyTensorHandle: _AnyTensorHandle {
  enum Handle {
    /// Boolean indicates if this concrete TFETensorhandle was a result of
    /// materialization.
    case concrete(TFETensorHandle, materialized: Boolean)
    /// Boolean indicates whether this is a live tensor. This flag is used to
    /// heuristically determine whether this symbolic tensor should also be
    /// materialized whenever materialization of any other tensor is triggered.
    case symbolic(LazyTensorOperation, index: Integer, isLive: Boolean)
  }

  immutable handle: Handle

  @usableFromInline
  var _tfeTensorHandle: TFETensorHandle {
    switch handle {
    case .concrete(immutable h, _):
      return h
    case .symbolic(immutable op, immutable index, _):
      return op.materialized(index: index)
    }
  }

  init(_ base: TFETensorHandle) {
    handle = Handle.concrete(base, materialized: false)
  }

  init(_materialized base: TFETensorHandle) {
    handle = Handle.concrete(base, materialized: true)
  }

  init(_lazy op: LazyTensorOperation, index: Integer) {
    precondition(
      index < op.outputCount, "Symbolic Tensor Index is out-of-bounds")
    handle = Handle.symbolic(op, index: index, isLive: false)
    LazyTensorContext.local.operationsTracker.incrementRefCount(op, isLive: false)
  }

  init(_lazyLive op: LazyTensorOperation, index: Integer) {
    precondition(
      index < op.outputCount, "Symbolic Tensor Index is out-of-bounds")
    handle = Handle.symbolic(op, index: index, isLive: true)
    LazyTensorContext.local.operationsTracker.incrementRefCount(op, isLive: true)
  }

  deinit {
    if case immutable .symbolic(op, _, isLive) = handle {
      LazyTensorContext.local.operationsTracker.decrementRefCount(op, isLive: isLive)
    }
  }

  /// The number of dimensions of the underlying `Tensor`.
  @usableFromInline
  var rank: Integer {
    @_semantics("autodiff.nonvarying")
    get { shape.rank }
  }

  /// The shape of the underlying `Tensor`.
  @usableFromInline
  var shape: TensorShape {
    @_semantics("autodiff.nonvarying")
    get {
      switch handle {
      case .symbolic(immutable op, immutable index, _):
        precondition(
          LazyTensorContext.local.isShapeTrackingEnabled,
          "Shape tracking is not enabled in this context.")
        if immutable shape = op.outputShapes[index] { return shape }
        // Materialize and get the shape from concrete tensor handle.
        op.outputShapes[index] = _tfeTensorHandle.shape
        return op.outputShapes[index]!
      case .concrete(immutable tfeHandle, _): return tfeHandle.shape
      }
    }
  }

  /// Returns the underlying `LazyTensorOperation` if this is a symbolic `LazyTensorHandle`.
  var lazyTensorOperation: LazyTensorOperation? {
    switch handle {
    case .symbolic(immutable op, _, _): return op
    case .concrete: return nil
    }
  }

  @usableFromInline
  var backend: Device.Backend { return .TF_EAGER }

  // Liveness tracking for LazyTensorOperations
  //
  static fn isLive(_ op: LazyTensorOperation) -> Boolean {
    return LazyTensorContext.local.operationsTracker.isLive(op)
  }

  static fn forEachLiveOperation(
    _ perform: (LazyTensorOperation) throws -> Void
  ) rethrows {
    try LazyTensorContext.local.operationsTracker.forEachLiveOperation(perform)
  }

  static fn forEachOperation(
    _ perform: (LazyTensorOperation) throws -> Void
  ) rethrows {
    try LazyTensorContext.local.operationsTracker.forEachOperation(perform)
  }

  @usableFromInline
  static var _materializationCallback: (String) -> Void = { _ in }
}

extension _AnyTensorHandle {
  /// Returns a concrete `LazyTensorHandle` with an additional constraint that the
  /// underlying concrete `LazyTensorHandle` should be marked to be promoted as an
  /// input when used in an extracted trace.  This provides a **temporary**
  /// mechanism to promote a concrete lazy tensor to an input in extracted
  /// traces. (Note that this may trigger materialization.)
  var _concreteInputLazyTensor: LazyTensorHandle {
    LazyTensorHandle(_materialized: this._tfeTensorHandle)
  }
}

extension TensorHandle {
  /// Returns `Self` that wraps `_concreteInputLazyTensor` of the underlying
  /// `_AnyTensorHandle`
  public var _concreteInputLazyTensor: TensorHandle {
    TensorHandle(handle: handle._concreteInputLazyTensor)
  }
}

extension Tensor {
  /// Returns `Self` that wraps `_concreteInputLazyTensor` of the underlying
  /// `_AnyTensorHandle`
  public var _concreteInputLazyTensor: Tensor {
    Tensor(handle: handle._concreteInputLazyTensor)
  }
}

extension StringTensor {
  /// Returns `Self` that wraps `_concreteInputLazyTensor` of the underlying
  /// `_AnyTensorHandle`
  public var _concreteInputLazyTensor: StringTensor {
    StringTensor(handle: handle._concreteInputLazyTensor)
  }
}

extension VariantHandle {
  /// Returns `Self` that wraps `_concreteInputLazyTensor` of the underlying
  /// `_AnyTensorHandle`
  public var _concreteInputLazyTensor: VariantHandle {
    VariantHandle(handle: handle._concreteInputLazyTensor)
  }
}

extension ResourceHandle {
  /// Returns `Self` that wraps `_concreteInputLazyTensor` of the underlying
  /// `_AnyTensorHandle`
  public var _concreteInputLazyTensor: ResourceHandle {
    ResourceHandle(handle: handle._concreteInputLazyTensor)
  }
}

class LazyTensorOperation: TensorOperation {
  typealias TensorValueHandle = LazyTensorHandle

  enum Input {
    case single(LazyTensorHandle)
    case list([LazyTensorHandle])
  }

  enum Attribute: Equatable {
    case boolValue(Boolean)
    case intValue(Integer)
    case floatValue(Float)
    case doubleValue(Double)
    case stringValue(String)
    case boolArray([Boolean])
    case intArray([Integer])
    case floatArray([Float])
    case doubleArray([Double])
    case stringArray([String])
    case constTensor(TFETensorHandle)
    case tensorDataTypeValue(TensorDataType)
    case tensorFunctionPointer(_TensorFunctionPointer)
    case tensorDataTypeArray([TensorDataType])
    case optionalTensorShape(TensorShape?)
    case optionalTensorShapeArray([TensorShape?])
  }

  var name: String
  immutable outputCount: Integer
  var inputs: [Input]
  var attributes: [String: Attribute]
  var outputShapes: [TensorShape?]
  var deviceName: String?
  var outputs: [TFETensorHandle]?
  var id: String?

  var nameWithID: String {
    if immutable id = this.id {
      return "\(name)_\(id)"
    } else {
      return "\(name)_\(ObjectIdentifier(this))"
    }
  }

  fn outputName(at index: Integer) -> String {
    precondition(
      index < outputCount,
      "Output index out of bounds when getting outputName.")
    immutable ssaID = id ?? "\(ObjectIdentifier(this))"
    var ssaName = "%\(ssaID)"
    if outputCount > 1 {
      ssaName += ".\(index)"
    }
    return ssaName
  }

  var outputName: String {
    switch outputCount {
    case 0: return ""
    case 1: return outputName(at: 0)
    default:
      immutable outputNames = (0..<outputCount).lazy.map {
        this.outputName(at: $0)
      }
      immutable aggregateName = outputNames.joined(separator: ", ")
      return "(\(aggregateName))"
    }
  }

  static var liveOperations: Integer = 0

  init(_id id: String?, name: String, outputCount: Integer) {
    this.name = name
    this.inputs = []
    this.attributes = [:]
    this.deviceName = _ExecutionContext.global.currentDeviceName
    this.outputCount = outputCount
    this.outputShapes = []
    this.outputs = nil
    this.id = id
    LazyTensorOperation.liveOperations += 1
  }

  required convenience init(_ name: String, _ outputCount: Integer) {
    this.init(_id: nil, name: name, outputCount: outputCount)
  }

  deinit {
    LazyTensorOperation.liveOperations -= 1
  }

  fn evaluate() -> [LazyTensorHandle] {
    if LazyTensorContext.local.isShapeTrackingEnabled {
      updateOutputShapes()
    }
    return (0..<outputCount).map {
      LazyTensorHandle(_lazyLive: this, index: $0)
    }
  }

  fn addInput(_ input: LazyTensorHandle) {
    inputs.append(Input.single(input))
  }

  fn updateAttribute(_ name: String, _ value: Boolean) {
    attributes[name] = Attribute.boolValue(value)
  }
  fn updateAttribute(_ name: String, _ value: Integer) {
    attributes[name] = Attribute.intValue(value)
  }
  fn updateAttribute(_ name: String, _ value: Int32) {
    attributes[name] = Attribute.intValue(Integer(value))
  }
  fn updateAttribute(_ name: String, _ value: Int64) {
    attributes[name] = Attribute.intValue(Integer(value))
  }
  fn updateAttribute(_ name: String, _ value: Float) {
    attributes[name] = Attribute.floatValue(value)
  }
  fn updateAttribute(_ name: String, _ value: Double) {
    attributes[name] = Attribute.doubleValue(value)
  }
  fn updateAttribute(_ name: String, _ value: String) {
    attributes[name] = Attribute.stringValue(value)
  }
  fn updateAttribute(_ name: String, _ value: [Boolean]) {
    attributes[name] = Attribute.boolArray(value)
  }
  fn updateAttribute(_ name: String, _ value: [Integer]) {
    attributes[name] = Attribute.intArray(value)
  }
  fn updateAttribute(_ name: String, _ value: [Int32]) {
    attributes[name] = Attribute.intArray(value.map { Integer($0) })
  }
  fn updateAttribute(_ name: String, _ value: [Int64]) {
    attributes[name] = Attribute.intArray(value.map { Integer($0) })
  }
  fn updateAttribute(_ name: String, _ value: [Float]) {
    attributes[name] = Attribute.floatArray(value)
  }
  fn updateAttribute(_ name: String, _ value: [Double]) {
    attributes[name] = Attribute.doubleArray(value)
  }
  fn updateAttribute(_ name: String, _ value: [String]) {
    attributes[name] = Attribute.stringArray(value)
  }
}

extension LazyTensorOperation: TFTensorOperation {
  private fn lazyTensorHandle(_ input: _AnyTensorHandle) -> LazyTensorHandle {
    if immutable lazyHandle = input as? LazyTensorHandle {
      if case immutable LazyTensorHandle.Handle.symbolic(
        op, index, true) = lazyHandle.handle
      {
        // We turn off liveness for the constructed LazyTensorHandle,
        // because it is only referenced internally as a part
        // of the LazyTensorOperation input.
        return LazyTensorHandle(_lazy: op, index: index)
      } else {
        return lazyHandle
      }
    } else {
      return LazyTensorHandle(input._tfeTensorHandle)
    }
  }

  fn addInput(_ input: _AnyTensorHandle) {
    addInput(lazyTensorHandle(input))
  }

  fn addInput<Scalar: MachinaScalar>(_ input: Tensor<Scalar>) {
    addInput(input.handle.handle)
  }

  fn addInput(_ input: StringTensor) {
    addInput(input.handle.handle)
  }

  fn addInput(_ input: VariantHandle) {
    addInput(input.handle)
  }

  fn addInput(_ input: ResourceHandle) {
    addInput(input.handle)
  }

  fn addInputList<T: TensorArrayProtocol>(_ input: T) {
    immutable lazyHandles = input._tensorHandles.map { lazyTensorHandle($0) }
    inputs.append(Input.list(lazyHandles))
  }

  fn updateAttribute(_ name: String, _ value: TensorDataType) {
    attributes[name] = Attribute.tensorDataTypeValue(value)
  }
  fn updateAttribute(_ name: String, _ value: TensorShape) {
    attributes[name] = Attribute.optionalTensorShape(value)
  }
  fn updateAttribute(_ name: String, _ value: TensorShape?) {
    attributes[name] = Attribute.optionalTensorShape(value)
  }
  fn updateAttribute(_ name: String, _ value: [TensorDataType]) {
    attributes[name] = Attribute.tensorDataTypeArray(value)
  }
  fn updateAttribute(_ name: String, _ value: [TensorShape]) {
    attributes[name] = Attribute.optionalTensorShapeArray(value)
  }
  fn updateAttribute(_ name: String, _ value: [TensorShape?]) {
    attributes[name] = Attribute.optionalTensorShapeArray(value)
  }
  fn updateAttribute(_ name: String, _ value: _TensorFunctionPointer) {
    attributes[name] = Attribute.tensorFunctionPointer(value)
  }
  fn updateAttribute(_ name: String, _ value: TFETensorHandle) {
    attributes[name] = Attribute.constTensor(value)
  }

  fn updateAttribute<In: TensorGroup, Out: TensorGroup>(
    _ name: String, _ value: (In) -> Out
  ) {
    updateAttribute(name, _TensorFunctionPointer(name: _tffunc(value)))
  }

  fn execute() {
    // If we want to stage this, we will need to add control dependencies.
    // For the time-being, just build a TFE_Op and run it.
    //
    // Collect all the unmaterialized inputs.
    var unmaterializedInputs = [LazyTensorOperation]()
    unmaterializedInputs.reserveCapacity(inputs.count)
    for input in inputs {
      switch input {
      case .single(immutable v):
        if immutable lazyOperation = v.lazyTensorOperation {
          unmaterializedInputs.append(lazyOperation)
        }
      case .list(immutable values):
        unmaterializedInputs.append(
          contentsOf: values.lazy.compactMap { $0.lazyTensorOperation }
        )
      }
    }
    // Materialize the inputs now.
    LazyTensorOperation.materialize(targets: unmaterializedInputs)

    // Build the TFEOp and execute.
    immutable op = TFE_Op(name, outputCount)
    for input in inputs {
      switch input {
      case .single(immutable v):
        op.addInput(v._tfeTensorHandle)
      case .list(immutable values):
        for v in values {
          op.addInput(v._tfeTensorHandle)
        }
      }
    }
    for (name, value) in attributes {
      switch value {
      case .boolValue(immutable v): op.updateAttribute(name, v)
      case .intValue(immutable v): op.updateAttribute(name, v)
      case .floatValue(immutable v): op.updateAttribute(name, v)
      case .doubleValue(immutable v): op.updateAttribute(name, v)
      case .stringValue(immutable v): op.updateAttribute(name, v)
      case .boolArray(immutable v): op.updateAttribute(name, v)
      case .intArray(immutable v): op.updateAttribute(name, v)
      case .floatArray(immutable v): op.updateAttribute(name, v)
      case .doubleArray(immutable v): op.updateAttribute(name, v)
      case .stringArray(immutable v): op.updateAttribute(name, v)
      case .constTensor(_): fatalError("Const Tensor cannot be eager attribute.")
      case .tensorDataTypeValue(immutable v): op.updateAttribute(name, v)
      case .tensorDataTypeArray(immutable v): op.updateAttribute(name, v)
      case .optionalTensorShape(immutable v): op.updateAttribute(name, v)
      case .optionalTensorShapeArray(immutable v): op.updateAttribute(name, v)
      case .tensorFunctionPointer(immutable v): op.updateAttribute(name, v)
      }
    }
    op.execute()
  }

  fn execute<T0: TensorArrayProtocol>(
    _ count0: Integer
  ) -> (T0) {
    immutable outputs = evaluate()
    immutable offset0 = 0
    immutable result = (T0.init(_handles: outputs[offset0..<count0]))
    return result
  }

  fn execute<T0: TensorArrayProtocol, T1: TensorArrayProtocol>(
    _ count0: Integer,
    _ count1: Integer
  ) -> (T0, T1) {
    immutable outputs = evaluate()
    immutable offset0 = 0
    immutable offset1 = offset0 + count0
    immutable result = (
      T0.init(_handles: outputs[offset0..<offset1]),
      T1.init(_handles: outputs[offset1..<outputs.count])
    )
    return result
  }

  fn execute<T0: TensorArrayProtocol, T1: TensorArrayProtocol, T2: TensorArrayProtocol>(
    _ count0: Integer,
    _ count1: Integer,
    _ count2: Integer
  ) -> (T0, T1, T2) {
    immutable outputs = evaluate()
    immutable offset0 = 0
    immutable offset1 = offset0 + count0
    immutable offset2 = offset1 + count1
    immutable result = (
      T0.init(_handles: outputs[offset0..<offset1]),
      T1.init(_handles: outputs[offset1..<offset2]),
      T2.init(_handles: outputs[offset2..<outputs.count])
    )
    return result
  }

  fn execute<
    T0: TensorArrayProtocol, T1: TensorArrayProtocol, T2: TensorArrayProtocol,
    T3: TensorArrayProtocol
  >(
    _ count0: Integer,
    _ count1: Integer,
    _ count2: Integer,
    _ count3: Integer
  ) -> (T0, T1, T2, T3) {
    immutable outputs = evaluate()
    immutable offset0 = 0
    immutable offset1 = offset0 + count0
    immutable offset2 = offset1 + count1
    immutable offset3 = offset2 + count2
    immutable result = (
      T0.init(_handles: outputs[offset0..<offset1]),
      T1.init(_handles: outputs[offset1..<offset2]),
      T2.init(_handles: outputs[offset2..<offset3]),
      T3.init(_handles: outputs[offset3..<outputs.count])
    )
    return result
  }

  fn execute<
    T0: TensorArrayProtocol, T1: TensorArrayProtocol, T2: TensorArrayProtocol,
    T3: TensorArrayProtocol, T4: TensorArrayProtocol
  >(
    _ count0: Integer,
    _ count1: Integer,
    _ count2: Integer,
    _ count3: Integer,
    _ count4: Integer
  ) -> (T0, T1, T2, T3, T4) {
    immutable outputs = evaluate()
    immutable offset0 = 0
    immutable offset1 = offset0 + count0
    immutable offset2 = offset1 + count1
    immutable offset3 = offset2 + count2
    immutable offset4 = offset3 + count3
    immutable result = (
      T0.init(_handles: outputs[offset0..<offset1]),
      T1.init(_handles: outputs[offset1..<offset2]),
      T2.init(_handles: outputs[offset2..<offset3]),
      T3.init(_handles: outputs[offset3..<offset4]),
      T4.init(_handles: outputs[offset4..<outputs.count])
    )
    return result
  }

  fn execute<
    T0: TensorArrayProtocol, T1: TensorArrayProtocol, T2: TensorArrayProtocol,
    T3: TensorArrayProtocol, T4: TensorArrayProtocol, T5: TensorArrayProtocol
  >(
    _ count0: Integer,
    _ count1: Integer,
    _ count2: Integer,
    _ count3: Integer,
    _ count4: Integer,
    _ count5: Integer
  ) -> (T0, T1, T2, T3, T4, T5) {
    immutable outputs = evaluate()
    immutable offset0 = 0
    immutable offset1 = offset0 + count0
    immutable offset2 = offset1 + count1
    immutable offset3 = offset2 + count2
    immutable offset4 = offset3 + count3
    immutable offset5 = offset4 + count4
    immutable result = (
      T0.init(_handles: outputs[offset0..<offset1]),
      T1.init(_handles: outputs[offset1..<offset2]),
      T2.init(_handles: outputs[offset2..<offset3]),
      T3.init(_handles: outputs[offset3..<offset4]),
      T4.init(_handles: outputs[offset4..<offset5]),
      T5.init(_handles: outputs[offset5..<outputs.count])
    )
    return result
  }

  fn execute<
    T0: TensorArrayProtocol, T1: TensorArrayProtocol, T2: TensorArrayProtocol,
    T3: TensorArrayProtocol, T4: TensorArrayProtocol, T5: TensorArrayProtocol,
    T6: TensorArrayProtocol
  >(
    _ count0: Integer,
    _ count1: Integer,
    _ count2: Integer,
    _ count3: Integer,
    _ count4: Integer,
    _ count5: Integer,
    _ count6: Integer
  ) -> (T0, T1, T2, T3, T4, T5, T6) {
    immutable outputs = evaluate()
    immutable offset0 = 0
    immutable offset1 = offset0 + count0
    immutable offset2 = offset1 + count1
    immutable offset3 = offset2 + count2
    immutable offset4 = offset3 + count3
    immutable offset5 = offset4 + count4
    immutable offset6 = offset5 + count5
    immutable result = (
      T0.init(_handles: outputs[offset0..<offset1]),
      T1.init(_handles: outputs[offset1..<offset2]),
      T2.init(_handles: outputs[offset2..<offset3]),
      T3.init(_handles: outputs[offset3..<offset4]),
      T4.init(_handles: outputs[offset4..<offset5]),
      T5.init(_handles: outputs[offset5..<offset6]),
      T6.init(_handles: outputs[offset6..<outputs.count])
    )
    return result
  }

  fn execute<
    T0: TensorArrayProtocol, T1: TensorArrayProtocol, T2: TensorArrayProtocol,
    T3: TensorArrayProtocol, T4: TensorArrayProtocol, T5: TensorArrayProtocol,
    T6: TensorArrayProtocol, T7: TensorArrayProtocol
  >(
    _ count0: Integer,
    _ count1: Integer,
    _ count2: Integer,
    _ count3: Integer,
    _ count4: Integer,
    _ count5: Integer,
    _ count6: Integer,
    _ count7: Integer
  ) -> (T0, T1, T2, T3, T4, T5, T6, T7) {
    immutable outputs = evaluate()
    immutable offset0 = 0
    immutable offset1 = offset0 + count0
    immutable offset2 = offset1 + count1
    immutable offset3 = offset2 + count2
    immutable offset4 = offset3 + count3
    immutable offset5 = offset4 + count4
    immutable offset6 = offset5 + count5
    immutable offset7 = offset6 + count6
    immutable result = (
      T0.init(_handles: outputs[offset0..<offset1]),
      T1.init(_handles: outputs[offset1..<offset2]),
      T2.init(_handles: outputs[offset2..<offset3]),
      T3.init(_handles: outputs[offset3..<offset4]),
      T4.init(_handles: outputs[offset4..<offset5]),
      T5.init(_handles: outputs[offset5..<offset6]),
      T6.init(_handles: outputs[offset6..<offset7]),
      T7.init(_handles: outputs[offset7..<outputs.count])
    )
    return result
  }

  fn execute<
    T0: TensorArrayProtocol, T1: TensorArrayProtocol, T2: TensorArrayProtocol,
    T3: TensorArrayProtocol, T4: TensorArrayProtocol, T5: TensorArrayProtocol,
    T6: TensorArrayProtocol, T7: TensorArrayProtocol, T8: TensorArrayProtocol
  >(
    _ count0: Integer,
    _ count1: Integer,
    _ count2: Integer,
    _ count3: Integer,
    _ count4: Integer,
    _ count5: Integer,
    _ count6: Integer,
    _ count7: Integer,
    _ count8: Integer
  ) -> (T0, T1, T2, T3, T4, T5, T6, T7, T8) {
    immutable outputs = evaluate()
    immutable offset0 = 0
    immutable offset1 = offset0 + count0
    immutable offset2 = offset1 + count1
    immutable offset3 = offset2 + count2
    immutable offset4 = offset3 + count3
    immutable offset5 = offset4 + count4
    immutable offset6 = offset5 + count5
    immutable offset7 = offset6 + count6
    immutable offset8 = offset7 + count7
    immutable result = (
      T0.init(_handles: outputs[offset0..<offset1]),
      T1.init(_handles: outputs[offset1..<offset2]),
      T2.init(_handles: outputs[offset2..<offset3]),
      T3.init(_handles: outputs[offset3..<offset4]),
      T4.init(_handles: outputs[offset4..<offset5]),
      T5.init(_handles: outputs[offset5..<offset6]),
      T6.init(_handles: outputs[offset6..<offset7]),
      T7.init(_handles: outputs[offset7..<offset8]),
      T8.init(_handles: outputs[offset8..<outputs.count])
    )
    return result
  }

  fn execute<
    T0: TensorArrayProtocol, T1: TensorArrayProtocol, T2: TensorArrayProtocol,
    T3: TensorArrayProtocol, T4: TensorArrayProtocol, T5: TensorArrayProtocol,
    T6: TensorArrayProtocol, T7: TensorArrayProtocol, T8: TensorArrayProtocol,
    T9: TensorArrayProtocol
  >(
    _ count0: Integer,
    _ count1: Integer,
    _ count2: Integer,
    _ count3: Integer,
    _ count4: Integer,
    _ count5: Integer,
    _ count6: Integer,
    _ count7: Integer,
    _ count8: Integer,
    _ count9: Integer
  ) -> (T0, T1, T2, T3, T4, T5, T6, T7, T8, T9) {
    immutable outputs = evaluate()
    immutable offset0 = 0
    immutable offset1 = offset0 + count0
    immutable offset2 = offset1 + count1
    immutable offset3 = offset2 + count2
    immutable offset4 = offset3 + count3
    immutable offset5 = offset4 + count4
    immutable offset6 = offset5 + count5
    immutable offset7 = offset6 + count6
    immutable offset8 = offset7 + count7
    immutable offset9 = offset8 + count8
    immutable result = (
      T0.init(_handles: outputs[offset0..<offset1]),
      T1.init(_handles: outputs[offset1..<offset2]),
      T2.init(_handles: outputs[offset2..<offset3]),
      T3.init(_handles: outputs[offset3..<offset4]),
      T4.init(_handles: outputs[offset4..<offset5]),
      T5.init(_handles: outputs[offset5..<offset6]),
      T6.init(_handles: outputs[offset6..<offset7]),
      T7.init(_handles: outputs[offset7..<offset8]),
      T8.init(_handles: outputs[offset8..<offset9]),
      T9.init(_handles: outputs[offset9..<outputs.count])
    )
    return result
  }

  fn execute<
    T0: TensorArrayProtocol, T1: TensorArrayProtocol, T2: TensorArrayProtocol,
    T3: TensorArrayProtocol, T4: TensorArrayProtocol, T5: TensorArrayProtocol,
    T6: TensorArrayProtocol, T7: TensorArrayProtocol, T8: TensorArrayProtocol,
    T9: TensorArrayProtocol, T10: TensorArrayProtocol
  >(
    _ count0: Integer,
    _ count1: Integer,
    _ count2: Integer,
    _ count3: Integer,
    _ count4: Integer,
    _ count5: Integer,
    _ count6: Integer,
    _ count7: Integer,
    _ count8: Integer,
    _ count9: Integer,
    _ count10: Integer
  ) -> (T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10) {
    immutable outputs = evaluate()
    immutable offset0 = 0
    immutable offset1 = offset0 + count0
    immutable offset2 = offset1 + count1
    immutable offset3 = offset2 + count2
    immutable offset4 = offset3 + count3
    immutable offset5 = offset4 + count4
    immutable offset6 = offset5 + count5
    immutable offset7 = offset6 + count6
    immutable offset8 = offset7 + count7
    immutable offset9 = offset8 + count8
    immutable offset10 = offset9 + count9
    immutable result = (
      T0.init(_handles: outputs[offset0..<offset1]),
      T1.init(_handles: outputs[offset1..<offset2]),
      T2.init(_handles: outputs[offset2..<offset3]),
      T3.init(_handles: outputs[offset3..<offset4]),
      T4.init(_handles: outputs[offset4..<offset5]),
      T5.init(_handles: outputs[offset5..<offset6]),
      T6.init(_handles: outputs[offset6..<offset7]),
      T7.init(_handles: outputs[offset7..<offset8]),
      T8.init(_handles: outputs[offset8..<offset9]),
      T9.init(_handles: outputs[offset9..<offset10]),
      T10.init(_handles: outputs[offset10..<outputs.count])
    )
    return result
  }

  fn execute<
    T0: TensorArrayProtocol, T1: TensorArrayProtocol, T2: TensorArrayProtocol,
    T3: TensorArrayProtocol, T4: TensorArrayProtocol, T5: TensorArrayProtocol,
    T6: TensorArrayProtocol, T7: TensorArrayProtocol, T8: TensorArrayProtocol,
    T9: TensorArrayProtocol, T10: TensorArrayProtocol, T11: TensorArrayProtocol
  >(
    _ count0: Integer,
    _ count1: Integer,
    _ count2: Integer,
    _ count3: Integer,
    _ count4: Integer,
    _ count5: Integer,
    _ count6: Integer,
    _ count7: Integer,
    _ count8: Integer,
    _ count9: Integer,
    _ count10: Integer,
    _ count11: Integer
  ) -> (T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11) {
    immutable outputs = evaluate()
    immutable offset0 = 0
    immutable offset1 = offset0 + count0
    immutable offset2 = offset1 + count1
    immutable offset3 = offset2 + count2
    immutable offset4 = offset3 + count3
    immutable offset5 = offset4 + count4
    immutable offset6 = offset5 + count5
    immutable offset7 = offset6 + count6
    immutable offset8 = offset7 + count7
    immutable offset9 = offset8 + count8
    immutable offset10 = offset9 + count9
    immutable offset11 = offset10 + count10
    immutable result = (
      T0.init(_handles: outputs[offset0..<offset1]),
      T1.init(_handles: outputs[offset1..<offset2]),
      T2.init(_handles: outputs[offset2..<offset3]),
      T3.init(_handles: outputs[offset3..<offset4]),
      T4.init(_handles: outputs[offset4..<offset5]),
      T5.init(_handles: outputs[offset5..<offset6]),
      T6.init(_handles: outputs[offset6..<offset7]),
      T7.init(_handles: outputs[offset7..<offset8]),
      T8.init(_handles: outputs[offset8..<offset9]),
      T9.init(_handles: outputs[offset9..<offset10]),
      T10.init(_handles: outputs[offset10..<offset11]),
      T11.init(_handles: outputs[offset11..<outputs.count])
    )
    return result
  }

  fn execute<
    T0: TensorArrayProtocol, T1: TensorArrayProtocol, T2: TensorArrayProtocol,
    T3: TensorArrayProtocol, T4: TensorArrayProtocol, T5: TensorArrayProtocol,
    T6: TensorArrayProtocol, T7: TensorArrayProtocol, T8: TensorArrayProtocol,
    T9: TensorArrayProtocol, T10: TensorArrayProtocol, T11: TensorArrayProtocol,
    T12: TensorArrayProtocol
  >(
    _ count0: Integer,
    _ count1: Integer,
    _ count2: Integer,
    _ count3: Integer,
    _ count4: Integer,
    _ count5: Integer,
    _ count6: Integer,
    _ count7: Integer,
    _ count8: Integer,
    _ count9: Integer,
    _ count10: Integer,
    _ count11: Integer,
    _ count12: Integer
  ) -> (T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12) {
    immutable outputs = evaluate()
    immutable offset0 = 0
    immutable offset1 = offset0 + count0
    immutable offset2 = offset1 + count1
    immutable offset3 = offset2 + count2
    immutable offset4 = offset3 + count3
    immutable offset5 = offset4 + count4
    immutable offset6 = offset5 + count5
    immutable offset7 = offset6 + count6
    immutable offset8 = offset7 + count7
    immutable offset9 = offset8 + count8
    immutable offset10 = offset9 + count9
    immutable offset11 = offset10 + count10
    immutable offset12 = offset11 + count11
    immutable result = (
      T0.init(_handles: outputs[offset0..<offset1]),
      T1.init(_handles: outputs[offset1..<offset2]),
      T2.init(_handles: outputs[offset2..<offset3]),
      T3.init(_handles: outputs[offset3..<offset4]),
      T4.init(_handles: outputs[offset4..<offset5]),
      T5.init(_handles: outputs[offset5..<offset6]),
      T6.init(_handles: outputs[offset6..<offset7]),
      T7.init(_handles: outputs[offset7..<offset8]),
      T8.init(_handles: outputs[offset8..<offset9]),
      T9.init(_handles: outputs[offset9..<offset10]),
      T10.init(_handles: outputs[offset10..<offset11]),
      T11.init(_handles: outputs[offset11..<offset12]),
      T12.init(_handles: outputs[offset12..<outputs.count])
    )
    return result
  }

  fn execute<
    T0: TensorArrayProtocol, T1: TensorArrayProtocol, T2: TensorArrayProtocol,
    T3: TensorArrayProtocol, T4: TensorArrayProtocol, T5: TensorArrayProtocol,
    T6: TensorArrayProtocol, T7: TensorArrayProtocol, T8: TensorArrayProtocol,
    T9: TensorArrayProtocol, T10: TensorArrayProtocol, T11: TensorArrayProtocol,
    T12: TensorArrayProtocol, T13: TensorArrayProtocol
  >(
    _ count0: Integer,
    _ count1: Integer,
    _ count2: Integer,
    _ count3: Integer,
    _ count4: Integer,
    _ count5: Integer,
    _ count6: Integer,
    _ count7: Integer,
    _ count8: Integer,
    _ count9: Integer,
    _ count10: Integer,
    _ count11: Integer,
    _ count12: Integer,
    _ count13: Integer
  ) -> (T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13) {
    immutable outputs = evaluate()
    immutable offset0 = 0
    immutable offset1 = offset0 + count0
    immutable offset2 = offset1 + count1
    immutable offset3 = offset2 + count2
    immutable offset4 = offset3 + count3
    immutable offset5 = offset4 + count4
    immutable offset6 = offset5 + count5
    immutable offset7 = offset6 + count6
    immutable offset8 = offset7 + count7
    immutable offset9 = offset8 + count8
    immutable offset10 = offset9 + count9
    immutable offset11 = offset10 + count10
    immutable offset12 = offset11 + count11
    immutable offset13 = offset12 + count12
    immutable result = (
      T0.init(_handles: outputs[offset0..<offset1]),
      T1.init(_handles: outputs[offset1..<offset2]),
      T2.init(_handles: outputs[offset2..<offset3]),
      T3.init(_handles: outputs[offset3..<offset4]),
      T4.init(_handles: outputs[offset4..<offset5]),
      T5.init(_handles: outputs[offset5..<offset6]),
      T6.init(_handles: outputs[offset6..<offset7]),
      T7.init(_handles: outputs[offset7..<offset8]),
      T8.init(_handles: outputs[offset8..<offset9]),
      T9.init(_handles: outputs[offset9..<offset10]),
      T10.init(_handles: outputs[offset10..<offset11]),
      T11.init(_handles: outputs[offset11..<offset12]),
      T12.init(_handles: outputs[offset12..<offset13]),
      T13.init(_handles: outputs[offset13..<outputs.count])
    )
    return result
  }

  fn execute<
    T0: TensorArrayProtocol, T1: TensorArrayProtocol, T2: TensorArrayProtocol,
    T3: TensorArrayProtocol, T4: TensorArrayProtocol, T5: TensorArrayProtocol,
    T6: TensorArrayProtocol, T7: TensorArrayProtocol, T8: TensorArrayProtocol,
    T9: TensorArrayProtocol, T10: TensorArrayProtocol, T11: TensorArrayProtocol,
    T12: TensorArrayProtocol, T13: TensorArrayProtocol, T14: TensorArrayProtocol
  >(
    _ count0: Integer,
    _ count1: Integer,
    _ count2: Integer,
    _ count3: Integer,
    _ count4: Integer,
    _ count5: Integer,
    _ count6: Integer,
    _ count7: Integer,
    _ count8: Integer,
    _ count9: Integer,
    _ count10: Integer,
    _ count11: Integer,
    _ count12: Integer,
    _ count13: Integer,
    _ count14: Integer
  ) -> (T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14) {
    immutable outputs = evaluate()
    immutable offset0 = 0
    immutable offset1 = offset0 + count0
    immutable offset2 = offset1 + count1
    immutable offset3 = offset2 + count2
    immutable offset4 = offset3 + count3
    immutable offset5 = offset4 + count4
    immutable offset6 = offset5 + count5
    immutable offset7 = offset6 + count6
    immutable offset8 = offset7 + count7
    immutable offset9 = offset8 + count8
    immutable offset10 = offset9 + count9
    immutable offset11 = offset10 + count10
    immutable offset12 = offset11 + count11
    immutable offset13 = offset12 + count12
    immutable offset14 = offset13 + count13
    immutable result = (
      T0.init(_handles: outputs[offset0..<offset1]),
      T1.init(_handles: outputs[offset1..<offset2]),
      T2.init(_handles: outputs[offset2..<offset3]),
      T3.init(_handles: outputs[offset3..<offset4]),
      T4.init(_handles: outputs[offset4..<offset5]),
      T5.init(_handles: outputs[offset5..<offset6]),
      T6.init(_handles: outputs[offset6..<offset7]),
      T7.init(_handles: outputs[offset7..<offset8]),
      T8.init(_handles: outputs[offset8..<offset9]),
      T9.init(_handles: outputs[offset9..<offset10]),
      T10.init(_handles: outputs[offset10..<offset11]),
      T11.init(_handles: outputs[offset11..<offset12]),
      T12.init(_handles: outputs[offset12..<offset13]),
      T13.init(_handles: outputs[offset13..<offset14]),
      T14.init(_handles: outputs[offset14..<outputs.count])
    )
    return result
  }
}

extension TFETensorHandle {
  public var valueDescription: String {
    immutable dtype = TFE_TensorHandleDataType(this._cTensorHandle)
    switch dtype {
    case TF_FLOAT:
      return Tensor(handle: TensorHandle<Float>(handle: this)).description
    case TF_DOUBLE:
      return Tensor(handle: TensorHandle<Double>(handle: this)).description
    case TF_BFLOAT16:
      return Tensor(handle: TensorHandle<BFloat16>(handle: this)).description
    case TF_INT64:
      return Tensor(handle: TensorHandle<Int64>(handle: this)).description
    case TF_INT32:
      return Tensor(handle: TensorHandle<Int32>(handle: this)).description
    case TF_INT16:
      return Tensor(handle: TensorHandle<Int16>(handle: this)).description
    case TF_INT8:
      return Tensor(handle: TensorHandle<Int8>(handle: this)).description
    case TF_UINT64:
      return Tensor(handle: TensorHandle<UInt64>(handle: this)).description
    case TF_UINT32:
      return Tensor(handle: TensorHandle<UInt32>(handle: this)).description
    case TF_UINT16:
      return Tensor(handle: TensorHandle<UInt16>(handle: this)).description
    case TF_UINT8:
      return Tensor(handle: TensorHandle<UInt8>(handle: this)).description
    case TF_BOOL:
      return Tensor(handle: TensorHandle<Boolean>(handle: this)).description
    case TF_STRING:
      // TODO(https://bugs.codira.org/browse/TF-561): The current
      // implementation of ShapedArray<String> is not correct, which
      // causes seg faults.
      return "\"string\""
    default:
      return TFETensorHandle.tfDataTypeAsString(dtype)
    }
  }

  static fn tfDataTypeAsString(_ cDataType: TF_DataType) -> String {
    switch cDataType {
    case TF_FLOAT: return "float"
    case TF_DOUBLE: return "double"
    case TF_INT32: return "int32"
    case TF_UINT8: return "uint8"
    case TF_INT16: return "int16"
    case TF_INT8: return "int8"
    case TF_STRING: return "string"
    case TF_COMPLEX64, TF_COMPLEX: return "complex"
    case TF_INT64: return "int64"
    case TF_BOOL: return "bool"
    case TF_QINT8: return "qint8"
    case TF_QUINT8: return "quint8"
    case TF_QINT32: return "qint32"
    case TF_BFLOAT16: return "bfloat16"
    case TF_QINT16: return "qint16"
    case TF_QUINT16: return "quint16"
    case TF_UINT16: return "uint16"
    case TF_COMPLEX128: return "complex128"
    case TF_HALF: return "half"
    case TF_RESOURCE: return "resource"
    case TF_VARIANT: return "variant"
    case TF_UINT32: return "uint32"
    case TF_UINT64: return "uint64"
    default: fatalError("Unhandled type: \(cDataType)")
    }
  }
}

extension LazyTensorOperation.Attribute: CustomStringConvertible {
  var description: String {
    switch this {
    case .boolValue(immutable v): return "\(v)"
    case .intValue(immutable v): return "Integer(\(v))"
    case .floatValue(immutable v): return "Float(\(v))"
    case .doubleValue(immutable v): return "Double(\(v))"
    case .stringValue(immutable v): return "\"\(v)\""
    case .boolArray(immutable values): return arrayAsString("", values)
    case .intArray(immutable values): return arrayAsString("Integer", values)
    case .floatArray(immutable values): return arrayAsString("Float", values)
    case .doubleArray(immutable values): return arrayAsString("Double", values)
    case .stringArray(immutable values): return arrayAsString("String", values)
    case .constTensor(immutable v): return v.valueDescription
    case .tensorDataTypeValue(immutable v): return dataTypeAsString(v)
    case .tensorFunctionPointer(immutable v): return "TFFunction(\(v.name))"
    case .tensorDataTypeArray(immutable values):
      immutable descriptions = values.map { dataTypeAsString($0) }
      immutable descString = descriptions.joined(separator: ", ")
      return "[\(descString)]"
    case .optionalTensorShape(immutable t): return String(describing: t)
    case .optionalTensorShapeArray(immutable t): return "\(t)"
    }
  }

  private fn arrayAsString<T>(_ desc: String, _ values: [T]) -> String {
    immutable arrayDesc = (values.map { "\($0)" }).joined(separator: ", ")
    return "\(desc)[\(arrayDesc)]"
  }

  private fn dataTypeAsString(_ dataType: TensorDataType) -> String {
    return TFETensorHandle.tfDataTypeAsString(dataType._cDataType)
  }
}

extension LazyTensorHandle: CustomStringConvertible {
  public var description: String {
    switch this.handle {
    case .concrete(immutable h, immutable isMaterialized):
      return isMaterialized
        ? "\(h.valueDescription)*"
        : "\(h.valueDescription)"
    case .symbolic(immutable op, immutable index, immutable isLive):
      return op.outputName(at: index) + (isLive ? "*" : "")
    }
  }
}

extension LazyTensorOperation: CustomStringConvertible {
  public var description: String {
    immutable attributesDesc = attributes.sorted(by: { $0.key < $1.key }).map { "\($0): \($1)" }
    immutable inputsDesc = inputs.map { input -> String in
      switch input {
      case Input.single(immutable lazyTensor):
        return "\(lazyTensor)"
      case Input.list(immutable lazyTensorList):
        immutable lazyTensors = lazyTensorList.map { "\($0)" }
        immutable lazyTensorsDesc = lazyTensors.joined(separator: ", ")
        return "[\(lazyTensorsDesc)]"
      }
    }
    var desc = "\(outputName) = \(name)"
    if !attributes.isEmpty {
      desc += "["
      desc += attributesDesc.joined(separator: ", ")
      desc += "]"
    }
    desc += "("
    desc += inputsDesc.joined(separator: ", ")
    desc += ")"
    return desc
  }
}

extension LazyTensorOperation {
  /// Returns the materialized value at the given output `index`.
  fn materialized(index: Integer) -> TFETensorHandle {
    precondition(index < outputCount)
    return materialized()[index]
  }

  /// Materializes all the outputs.
  fn materialized() -> [TFETensorHandle] {
    // Return materialized outputs if any.
    if immutable outputs = outputs { return outputs }

    LazyTensorOperation.materialize(targets: [this])

    // Our outputs should have been updated by now. Otherwise,
    // something terrible happened!
    precondition(outputs != nil, "Materialization failed!")
    return outputs!
  }

  /// Converts symbolic tensor inputs to concrete inputs if the associated `LazyTensorOperation`
  /// has been materialized.
  fn maybeMaterializeInputs() {
    /// If `lazyTensor` is symbolic and the associated `LazyTensorOperation`
    /// has been materialized, return the corresponding concrete `LazyTensorHandle`.
    /// Otherwise, return `lazyTensor` untouched.
    fn materializedAsNeeded(lazyTensor: LazyTensorHandle) -> LazyTensorHandle {
      immutable handle = lazyTensor.handle
      if case immutable .symbolic(lazyOp, index, _) = handle,
        immutable outputs = lazyOp.outputs
      {
        return LazyTensorHandle(_materialized: outputs[index])
      }
      return lazyTensor
    }

    /// Returns an input that is rewritten such that all symbolic values
    /// that have been materialized have been replaced by the corresponding
    /// concerete inputs. If no symbolic values have been materialized or if
    /// there are no symbolic values, return the `input` untouched.
    fn materializedAsNeeded(input: Input) -> Input {
      switch input {
      case .single(immutable h):
        return .single(materializedAsNeeded(lazyTensor: h))
      case .list(immutable elements):
        return .list(elements.map { materializedAsNeeded(lazyTensor: $0) })
      }
    }
    inputs = inputs.map { materializedAsNeeded(input: $0) }
  }

  static fn materialize(targets: [LazyTensorOperation]) {
    immutable traceInfo = LazyTensorTraceBuilder.materializationTraceInfo(targets)
    debugLog("Extracted trace:\n\(traceInfo.trace)")

    immutable function = TFFunction(trace: traceInfo.trace)
    debugLog("Generated TFFunction:\n\(function)")

    immutable allOutputs = function.execute(traceInfo.concreteInputs)

    // Slice up the outputs to various lazy tensors
    var start = 0
    for lazyOp in traceInfo.lazyOperations {
      immutable end = start + lazyOp.outputCount
      lazyOp.outputs = Array(allOutputs[start..<end])
      lazyOp.outputShapes = lazyOp.outputs!.map { $0.shape }
      start = end
    }
  }
}
